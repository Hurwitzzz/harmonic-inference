{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from harmonic_inference.data.data_types import PitchType, KeyMode, TRIAD_REDUCTION\n",
    "from harmonic_inference.data.piece import ScorePiece\n",
    "from harmonic_inference.data.corpus_reading import load_clean_corpus_dfs\n",
    "import harmonic_inference.utils.harmonic_utils as hu\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df, measures_df, chords_df, notes_df = load_clean_corpus_dfs('corpus_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composers = sorted(set(name.split('-')[0].strip() for name in files_df.corpus_name.unique()))\n",
    "composers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data directories\n",
    "base_dir = Path(\"ML_course_data\")\n",
    "\n",
    "chord_dir = Path(base_dir / \"chord\")\n",
    "shutil.rmtree(chord_dir, ignore_errors=True)\n",
    "chord_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "key_dir = Path(base_dir / \"key\")\n",
    "shutil.rmtree(key_dir, ignore_errors=True)\n",
    "key_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_reduction = TRIAD_REDUCTION\n",
    "use_inversions = False\n",
    "use_relative = False\n",
    "\n",
    "chord_labels = {KeyMode.MAJOR: set(), KeyMode.MINOR: set()}\n",
    "key_labels = {KeyMode.MAJOR: set(), KeyMode.MINOR: set()}\n",
    "\n",
    "for composer in composers:\n",
    "    # startswith instead of contains because of WFBach/Bach\n",
    "    composer_df = files_df.loc[files_df[\"corpus_name\"].str.startswith(composer)]\n",
    "\n",
    "    for file_id, file_row in tqdm(\n",
    "        composer_df.iterrows(),\n",
    "        desc=f\"Creating {composer} data\",\n",
    "        total=len(composer_df),\n",
    "    ):\n",
    "        try:\n",
    "            piece = ScorePiece(\n",
    "                notes_df.loc[file_id],\n",
    "                chords_df.loc[file_id],\n",
    "                measures_df.loc[file_id],\n",
    "                chord_reduction=chord_reduction,\n",
    "                use_inversions=use_inversions,\n",
    "                use_relative=use_relative,\n",
    "                name=f\"{file_id}: {file_row['corpus_name']}\",\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"No data created for file_id {file_id}\")\n",
    "            logging.exception(e)\n",
    "            continue\n",
    "\n",
    "        with open(key_dir / f\"{composer}.csv\", \"a+\") as key_file:\n",
    "            key_symbols = [\n",
    "                hu.get_scale_degree_from_interval(key.local_tonic - key.global_tonic, key.global_mode, PitchType.TPC)\n",
    "                + \":\" + str(key.local_mode).split('.')[1]\n",
    "                for key in piece.get_keys()\n",
    "            ]\n",
    "            key_labels[piece.get_keys()[0].global_mode].add([symbol for symbol in key_symbols])\n",
    "            key_file.write(\",\".join(key_symbols) + \"\\n\")\n",
    "\n",
    "        with open(chord_dir / f\"{composer}.csv\", \"a+\") as chord_file:\n",
    "            for start, end in zip(\n",
    "                piece.get_key_change_indices(),\n",
    "                list(piece.get_key_change_indices()[1:]) + [len(piece.get_chords())]\n",
    "            ):\n",
    "                mode = piece.get_chords()[start].key_mode\n",
    "                chord_symbols = [\n",
    "                    hu.get_scale_degree_from_interval(chord.root - chord.key_tonic, mode, PitchType.TPC) +\n",
    "                    \":\" + str(chord.chord_type).split('.')[1][:3]\n",
    "                    for chord in piece.get_chords()[start:end]\n",
    "                ]\n",
    "                chord_labels[mode].add([symbol for symbol in chord_symbols])\n",
    "                chord_file.write(str(mode).split(\".\")[1] + \";\" + \",\".join(chord_symbols) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(base_dir / \"chord_vocab_major.txt\").write_text(\"\\n\".join(sorted(chord_labels[KeyMode.MAJOR])))\n",
    "Path(base_dir / \"chord_vocab_minor.txt\").write_text(\"\\n\".join(sorted(chord_labels[KeyMode.MINOR])))\n",
    "Path(base_dir / \"chord_vocab_full.txt\").write_text(\n",
    "    \"\\n\".join(sorted(set(list(chord_labels[KeyMode.MINOR]) + list(chord_labels[KeyMode.MAJOR]))))\n",
    ")\n",
    "\n",
    "Path(base_dir / \"key_vocab_major.txt\").write_text(\"\\n\".join(sorted(key_labels[KeyMode.MAJOR])))\n",
    "Path(base_dir / \"key_vocab_minor.txt\").write_text(\"\\n\".join(sorted(key_labels[KeyMode.MINOR])))\n",
    "Path(base_dir / \"key_vocab_full.txt\").write_text(\n",
    "    \"\\n\".join(sorted(set(list(key_labels[KeyMode.MINOR]) + list(key_labels[KeyMode.MAJOR]))))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate labels from csv, if necessary\n",
    "chord_labels = {KeyMode.MAJOR: set(), KeyMode.MINOR: set()}\n",
    "key_labels = {KeyMode.MAJOR: set(), KeyMode.MINOR: set()}\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "for path in glob('ML_course_data/chord/*.csv'):\n",
    "    with open(path, 'r') as fp:\n",
    "        for line in fp:\n",
    "            key_label, chords = line.strip().split(\";\")\n",
    "\n",
    "            label_set = chord_labels[KeyMode.MAJOR] if key_label == \"MAJOR\" else chord_labels[KeyMode.MINOR]\n",
    "            for label in chords.split(\",\"):\n",
    "                label_set.add(label)\n",
    "\n",
    "for path in glob('ML_course_data/key/*.csv'):\n",
    "    with open(path, 'r') as fp:\n",
    "        for line in fp:\n",
    "            keys = line.strip().split(\",\")\n",
    "            key_label = keys[0].split(\":\")[1]\n",
    "\n",
    "            label_set = key_labels[KeyMode.MAJOR] if key_label == \"MAJOR\" else key_labels[KeyMode.MINOR]\n",
    "            for label in keys:\n",
    "                label_set.add(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making labels version 2: numeral/chord_type/relativeroots\n",
    "\n",
    "# Make data directories\n",
    "base_dir = Path(\"ML_course_data\")\n",
    "\n",
    "chord_dir = Path(base_dir / \"chord_v2\")\n",
    "shutil.rmtree(chord_dir, ignore_errors=True)\n",
    "chord_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-create\n",
    "chord_type_reduction = {\n",
    "    '': ['M', 'm', 'Mm7', 'mm7', 'MM7', 'mM7'],\n",
    "    'o': ['o', 'o7', '%7'],\n",
    "    '+': ['+', '+7'],\n",
    "}\n",
    "use_inversions = False\n",
    "\n",
    "# Only save important columns\n",
    "if use_inversions:\n",
    "    label_columns = [\"numeral\", \"chord_type\", \"figbass\", \"relativeroot\"]\n",
    "else:\n",
    "    label_columns = [\"numeral\", \"chord_type\", \"relativeroot\"]\n",
    "\n",
    "key_columns = [\"globalkey\", \"globalkey_is_minor\", \"localkey\", \"localkey_is_minor\"]\n",
    "all_columns = label_columns + key_columns\n",
    "\n",
    "chords_df_v2 = chords_df.loc[~chords_df.numeral.isnull(), all_columns].copy()\n",
    "\n",
    "# Add / to front of non-empty relative roots\n",
    "chords_df_v2.loc[~chords_df_v2[\"relativeroot\"].isnull(), [\"relativeroot\"]] = (\n",
    "    \"/\" + chords_df_v2.loc[~chords_df_v2[\"relativeroot\"].isnull(), [\"relativeroot\"]]\n",
    ")\n",
    "\n",
    "# Reduce chord types\n",
    "for new_type, orig_types in chord_type_reduction.items():\n",
    "    chords_df_v2.loc[chords_df_v2[\"chord_type\"].isin(orig_types), \"chord_type\"] = new_type\n",
    "\n",
    "# Fill null cells with empty string\n",
    "chords_df_v2 = chords_df_v2.fillna(\"\")\n",
    "\n",
    "# Concatenate important columns\n",
    "chords_df_v2[\"label\"] = chords_df_v2[columns].values.sum(axis=1)\n",
    "\n",
    "for composer in composers:\n",
    "    # startswith instead of contains because of WFBach/Bach\n",
    "    composer_df = files_df.loc[files_df[\"corpus_name\"].str.startswith(composer)]\n",
    "\n",
    "    for file_id, file_row in tqdm(\n",
    "        composer_df.iterrows(),\n",
    "        desc=f\"Creating {composer} data\",\n",
    "        total=len(composer_df),\n",
    "    ):\n",
    "        try:\n",
    "            this_chords_df = chords_df_v2.loc[file_id]\n",
    "        except:\n",
    "            logging.warning(\"No chord data for file_id %s\", file_id)\n",
    "            continue\n",
    "\n",
    "        key_changes = (\n",
    "            this_chords_df[key_columns].shift() != this_chords_df[key_columns]\n",
    "        ).any(axis=1)\n",
    "        key_indexes = list(this_chords_df.index[key_changes])\n",
    "\n",
    "        for key_start, key_end in zip(key_indexes, key_indexes[1:] + [None]):\n",
    "            if key_end is not None:\n",
    "                key_end -= 1\n",
    "\n",
    "            this_key_chords_df = this_chords_df.loc[key_start:key_end]\n",
    "            key_string = \"MINOR\" if this_key_chords_df.iloc[0][\"localkey_is_minor\"] else \"MAJOR\"\n",
    "            chord_changes = this_key_chords_df[\"label\"].shift() != this_key_chords_df[\"label\"]\n",
    "\n",
    "            labels_list = list(this_key_chords_df.loc[chord_changes, \"label\"])\n",
    "\n",
    "            # Write out to file\n",
    "            with open(chord_dir / f\"{composer}.csv\", \"a+\") as chord_file:\n",
    "                chord_file.write(key_string + \";\" + \",\".join(labels_list) + \"\\n\")\n"
   ]
  }
 ]
}