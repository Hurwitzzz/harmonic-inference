{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('harmony': conda)",
   "display_name": "Python 3.7.9 64-bit ('harmony': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a191b7ca072ee042befe415e9c73f471d3b801044783c4feae37afcfb1965ba9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from harmonic_inference.data.piece import Piece, ScorePiece\n",
    "import harmonic_inference.models.initial_chord_models as icm\n",
    "from harmonic_inference.data.corpus_reading import load_clean_corpus_dfs\n",
    "from harmonic_inference.models.joint_model import MODEL_CLASSES, HarmonicInferenceModel, DebugLogger\n",
    "import harmonic_inference.data.datasets as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_df, measures_df, chords_df, notes_df = load_clean_corpus_dfs('corpus_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model paths\n",
    "model_paths = {}\n",
    "\n",
    "for model in MODEL_CLASSES.keys():\n",
    "    if model == \"icm\":\n",
    "        continue\n",
    "\n",
    "    model_paths[model] = os.path.join(\n",
    "        \"checkpoints\", model, \"lightning_logs\", \"version_*\", \"checkpoints\", \"*.ckpt\"\n",
    "    )\n",
    "\n",
    "model_paths[\"icm\"] = os.path.join(\"checkpoints\", \"icm\", \"initial_chord_prior.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "models = {}\n",
    "for model_name, model_class in MODEL_CLASSES.items():\n",
    "    if model_name == \"icm\":\n",
    "        continue\n",
    "\n",
    "    possible_checkpoints = sorted(glob(model_paths[model_name]))\n",
    "    if len(possible_checkpoints) == 0:\n",
    "        logging.error(f\"No checkpoints found for {model_name} in {model_paths[model_name]}\")\n",
    "        sys.exit(2)\n",
    "\n",
    "    if len(possible_checkpoints) == 1:\n",
    "        checkpoint = possible_checkpoints[0]\n",
    "        logging.info(f\"Loading checkpoint {checkpoint} for {model_name}.\")\n",
    "\n",
    "    else:\n",
    "        checkpoint = possible_checkpoints[0]\n",
    "        logging.info(f\"Multiple checkpoints found for {model_name}. Loading {checkpoint}.\")\n",
    "\n",
    "    models[model_name] = model_class.load_from_checkpoint(checkpoint)\n",
    "    models[model_name].freeze()\n",
    "\n",
    "# Load icm json differently\n",
    "logging.info(f\"Loading checkpoint {model_paths['icm']} for icm.\")\n",
    "models[\"icm\"] = icm.SimpleInitialChordModel(model_paths[\"icm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_dir = Path(\"h5_data\")\n",
    "seed = 0\n",
    "\n",
    "# Load validation data for ctm\n",
    "h5_path = Path(h5_dir / f\"ChordTransitionDataset_valid_seed_{seed}.h5\")\n",
    "with h5py.File(h5_path, \"r\") as h5_file:\n",
    "    if \"file_ids\" not in h5_file:\n",
    "        logging.error(f\"file_ids not found in {h5_path}. Re-create with create_h5_data.py\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    file_ids = list(h5_file[\"file_ids\"])\n",
    "\n",
    "# Load from pkl if available\n",
    "pkl_path = Path(h5_dir / f\"pieces_valid_seed_{seed}.pkl\")\n",
    "if pkl_path.exists():\n",
    "    with open(pkl_path, \"rb\") as pkl_file:\n",
    "        piece_dicts = pickle.load(pkl_file)\n",
    "else:\n",
    "    piece_dicts = [None] * len(file_ids)\n",
    "\n",
    "pieces = [\n",
    "    ScorePiece(\n",
    "        notes_df.loc[file_id],\n",
    "        chords_df.loc[file_id],\n",
    "        measures_df.loc[file_id],\n",
    "        piece_dict=piece_dict,\n",
    "        name=(\n",
    "            f\"{file_id}: {files_df.loc[file_id, 'corpus_name']}/\"\n",
    "            f\"{files_df.loc[file_id, 'file_name']}\"\n",
    "        ),\n",
    "    ) for file_id, piece_dict in tqdm(\n",
    "        zip(file_ids, piece_dicts),\n",
    "        total=len(file_ids),\n",
    "        desc=\"Loading pieces\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_classes = {\n",
    "    \"ccm\": ds.ChordClassificationDataset,\n",
    "    \"ctm\": ds.ChordTransitionDataset,\n",
    "    \"csm\": ds.ChordSequenceDataset,\n",
    "    \"ktm\": ds.KeyTransitionDataset,\n",
    "    \"ksm\": ds.KeySequenceDataset,\n",
    "}\n",
    "\n",
    "# Load and evaluate validation data\n",
    "for model_name, model in models.items():\n",
    "    logging.info(f\"Evaluating {model_name}\")\n",
    "    if model_name == \"icm\":\n",
    "        logging.info(model.evaluate(pieces))\n",
    "        continue\n",
    "\n",
    "    dataset = dataset_classes[model_name]\n",
    "    h5_path_valid = Path(h5_dir / f\"{dataset.__name__}_valid_seed_{seed}.h5\")\n",
    "    dataset_valid = ds.h5_to_dataset(h5_path_valid, dataset, transform=torch.from_numpy)\n",
    "\n",
    "    logging.info(model.evaluate(dataset_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f\"{i}: {piece.name}\" for i, piece in enumerate(pieces)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose random piece\n",
    "np.random.seed()\n",
    "\n",
    "piece_index = np.random.choice(len(pieces))\n",
    "piece = pieces[piece_index]\n",
    "\n",
    "file_id, piece_name = [string.strip() for string in piece.name.split(':')]\n",
    "\n",
    "logging.info(f\"Evaluating piece file_id={file_id}: {piece_name}\")\n",
    "\n",
    "joint_model = HarmonicInferenceModel(\n",
    "    models,\n",
    "    min_chord_change_prob=0.15,\n",
    "    max_no_chord_change_prob=0.85,\n",
    ")\n",
    "\n",
    "# Normally, just run joint_model.get_harmony(piece)\n",
    "# Here, we are running it manually\n",
    "joint_model.current_piece = piece\n",
    "\n",
    "# Save caches from piece\n",
    "joint_model.duration_cache = piece.get_duration_cache()\n",
    "joint_model.onset_cache = [vec.onset for vec in piece.get_inputs()] + [\n",
    "    piece.get_inputs()[-1].offset\n",
    "]\n",
    "joint_model.onset_level_cache = [vec.onset_level for vec in piece.get_inputs()] + [\n",
    "    piece.get_inputs()[-1].offset_level\n",
    "]\n",
    "\n",
    "joint_model.debugger = DebugLogger(\n",
    "    joint_model.current_piece,\n",
    "    joint_model.CHORD_OUTPUT_TYPE,\n",
    "    joint_model.KEY_OUTPUT_TYPE,\n",
    "    joint_model.max_chord_branching_factor,\n",
    "    joint_model.max_key_branching_factor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Chord Transition Model\n",
    "chord_change_probs = joint_model.get_chord_change_probs()\n",
    "chord_ranges, chord_range_log_probs = joint_model.get_chord_ranges(chord_change_probs)\n",
    "\n",
    "joint_model.debugger.debug_chord_change_probs(chord_change_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many changes are missed?\n",
    "chord_change_indices = list(piece.get_chord_change_indices())\n",
    "\n",
    "missed = 0\n",
    "for i, (start, end) in enumerate(zip(chord_change_indices, chord_change_indices[1:] + [len(piece.get_inputs())])):\n",
    "    correct_range = (start, end)\n",
    "    if correct_range not in chord_ranges:\n",
    "        print(f\"Chord range {correct_range} not found (chord {i})\")\n",
    "        missed += 1\n",
    "\n",
    "print(f\"Missed {missed} out of {len(chord_change_indices)} ranges\")\n",
    "print(f\"Accuracy = {1 - missed / len(chord_change_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Chord Classification Model\n",
    "chord_classifications = joint_model.get_chord_classifications(chord_ranges)\n",
    "joint_model.debugger.debug_chord_classifications(chord_ranges, chord_classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}