{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('harmony': conda)",
   "display_name": "Python 3.7.9 64-bit ('harmony': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a191b7ca072ee042befe415e9c73f471d3b801044783c4feae37afcfb1965ba9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "from harmonic_inference.data.piece import Piece, ScorePiece\n",
    "import harmonic_inference.models.initial_chord_models as icm\n",
    "from harmonic_inference.data.corpus_reading import load_clean_corpus_dfs\n",
    "from harmonic_inference.models.joint_model import MODEL_CLASSES, HarmonicInferenceModel\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_df, measures_df, chords_df, notes_df = load_clean_corpus_dfs('corpus_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model paths\n",
    "model_paths = {}\n",
    "\n",
    "for model in MODEL_CLASSES.keys():\n",
    "    if model == \"icm\":\n",
    "        continue\n",
    "\n",
    "    model_paths[model] = os.path.join(\n",
    "        \"checkpoints\", model, \"lightning_logs\", \"version_*\", \"checkpoints\", \"*.ckpt\"\n",
    "    )\n",
    "\n",
    "model_paths[\"icm\"] = os.path.join(\"checkpoints\", \"icm\", \"initial_chord_prior.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "models = {}\n",
    "for model_name, model_class in MODEL_CLASSES.items():\n",
    "    if model_name == \"icm\":\n",
    "        continue\n",
    "\n",
    "    possible_checkpoints = sorted(glob(model_paths[model_name]))\n",
    "    if len(possible_checkpoints) == 0:\n",
    "        logging.error(f\"No checkpoints found for {model_name} in {model_paths[model_name]}\")\n",
    "        sys.exit(2)\n",
    "\n",
    "    if len(possible_checkpoints) == 1:\n",
    "        checkpoint = possible_checkpoints[0]\n",
    "        logging.info(f\"Loading checkpoint {checkpoint} for {model_name}.\")\n",
    "\n",
    "    else:\n",
    "        checkpoint = possible_checkpoints[0]\n",
    "        logging.info(f\"Multiple checkpoints found for {model_name}. Loading {checkpoint}.\")\n",
    "\n",
    "    models[model_name] = model_class.load_from_checkpoint(checkpoint)\n",
    "    models[model_name].freeze()\n",
    "\n",
    "# Load icm json differently\n",
    "logging.info(f\"Loading checkpoint {model_paths['icm']} for icm.\")\n",
    "models[\"icm\"] = icm.SimpleInitialChordModel(model_paths[\"icm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_dir = Path(\"h5_data\")\n",
    "seed = 0\n",
    "\n",
    "# Load validation data for ctm\n",
    "h5_path = Path(h5_dir / f\"ChordTransitionDataset_valid_seed_{seed}.h5\")\n",
    "with h5py.File(h5_path, \"r\") as h5_file:\n",
    "    if \"file_ids\" not in h5_file:\n",
    "        logging.error(f\"file_ids not found in {h5_path}. Re-create with create_h5_data.py\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    file_ids = list(h5_file[\"file_ids\"])\n",
    "\n",
    "# Load from pkl if available\n",
    "pkl_path = Path(h5_dir / f\"pieces_valid_seed_{seed}.pkl\")\n",
    "if pkl_path.exists():\n",
    "    with open(pkl_path, \"rb\") as pkl_file:\n",
    "        piece_dicts = pickle.load(pkl_file)\n",
    "    pieces = [\n",
    "        ScorePiece(\n",
    "            None,\n",
    "            None,\n",
    "            measures_df.loc[file_id],\n",
    "            piece_dict=piece_dict,\n",
    "            name=f\"{file_id}: {files_df.loc[file_id, 'corpus_name']}/{files_df.loc[file_id, 'file_name']}\",\n",
    "        )\n",
    "        for file_id, piece_dict in zip(file_ids, piece_dicts)\n",
    "    ]\n",
    "\n",
    "# Generate from dfs\n",
    "else:\n",
    "    pieces = []\n",
    "    for file_id in tqdm(file_ids, desc=\"Loading Pieces\"):\n",
    "        pieces.append(\n",
    "            ScorePiece(\n",
    "                notes_df.loc[file_id],\n",
    "                chords_df.loc[file_id],\n",
    "                measures_df.loc[file_id],\n",
    "                name=f\"{file_id}: {files_df.loc[file_id, 'corpus_name']}/{files_df.loc[file_id, 'file_name']}\",\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = HarmonicInferenceModel(models)\n",
    "\n",
    "state = model.get_harmony(pieces[0])\n",
    "print(eu.evaluate(pieces[0], state))"
   ]
  }
 ]
}