{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('harmony': conda)",
   "display_name": "Python 3.7.9 64-bit ('harmony': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a191b7ca072ee042befe415e9c73f471d3b801044783c4feae37afcfb1965ba9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from harmonic_inference.data.piece import Piece, ScorePiece, get_range_start\n",
    "import harmonic_inference.models.initial_chord_models as icm\n",
    "from harmonic_inference.data.corpus_reading import load_clean_corpus_dfs\n",
    "from harmonic_inference.models.joint_model import MODEL_CLASSES, HarmonicInferenceModel, DebugLogger\n",
    "import harmonic_inference.data.datasets as ds\n",
    "from harmonic_inference.data.data_types import KeyMode\n",
    "from harmonic_inference.utils.beam_search_utils import State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_df, measures_df, chords_df, notes_df = load_clean_corpus_dfs('corpus_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model paths\n",
    "model_paths = {}\n",
    "\n",
    "for model in MODEL_CLASSES.keys():\n",
    "    if model == \"icm\":\n",
    "        continue\n",
    "\n",
    "    model_paths[model] = os.path.join(\n",
    "        \"checkpoints\", model, \"lightning_logs\", \"version_*\", \"checkpoints\", \"*.ckpt\"\n",
    "    )\n",
    "\n",
    "model_paths[\"icm\"] = os.path.join(\"checkpoints\", \"icm\", \"initial_chord_prior.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "models = {}\n",
    "for model_name, model_class in MODEL_CLASSES.items():\n",
    "    if model_name == \"icm\":\n",
    "        continue\n",
    "\n",
    "    possible_checkpoints = sorted(glob(model_paths[model_name]))\n",
    "    if len(possible_checkpoints) == 0:\n",
    "        logging.error(f\"No checkpoints found for {model_name} in {model_paths[model_name]}\")\n",
    "        sys.exit(2)\n",
    "\n",
    "    if len(possible_checkpoints) == 1:\n",
    "        checkpoint = possible_checkpoints[0]\n",
    "        logging.info(f\"Loading checkpoint {checkpoint} for {model_name}.\")\n",
    "\n",
    "    else:\n",
    "        checkpoint = possible_checkpoints[-1]\n",
    "        logging.info(f\"Multiple checkpoints found for {model_name}. Loading {checkpoint}.\")\n",
    "\n",
    "    models[model_name] = model_class.load_from_checkpoint(checkpoint)\n",
    "    models[model_name].freeze()\n",
    "\n",
    "# Load icm json differently\n",
    "logging.info(f\"Loading checkpoint {model_paths['icm']} for icm.\")\n",
    "models[\"icm\"] = icm.SimpleInitialChordModel(model_paths[\"icm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_dir = Path(\"h5_data\")\n",
    "seed = 0\n",
    "\n",
    "# Load validation data for ctm\n",
    "h5_path = Path(h5_dir / f\"ChordTransitionDataset_valid_seed_{seed}.h5\")\n",
    "with h5py.File(h5_path, \"r\") as h5_file:\n",
    "    if \"file_ids\" not in h5_file:\n",
    "        logging.error(f\"file_ids not found in {h5_path}. Re-create with create_h5_data.py\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    file_ids = list(h5_file[\"file_ids\"])\n",
    "\n",
    "# Load from pkl if available\n",
    "pkl_path = Path(h5_dir / f\"pieces_valid_seed_{seed}.pkl\")\n",
    "if pkl_path.exists():\n",
    "    with open(pkl_path, \"rb\") as pkl_file:\n",
    "        piece_dicts = pickle.load(pkl_file)\n",
    "else:\n",
    "    piece_dicts = [None] * len(file_ids)\n",
    "\n",
    "pieces = [\n",
    "    ScorePiece(\n",
    "        notes_df.loc[file_id],\n",
    "        chords_df.loc[file_id],\n",
    "        measures_df.loc[file_id],\n",
    "        piece_dict=piece_dict,\n",
    "        name=(\n",
    "            f\"{file_id}: {files_df.loc[file_id, 'corpus_name']}/\"\n",
    "            f\"{files_df.loc[file_id, 'file_name']}\"\n",
    "        ),\n",
    "    ) for file_id, piece_dict in tqdm(\n",
    "        zip(file_ids, piece_dicts),\n",
    "        total=len(file_ids),\n",
    "        desc=\"Loading pieces\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_classes = {\n",
    "    \"ccm\": ds.ChordClassificationDataset,\n",
    "    \"ctm\": ds.ChordTransitionDataset,\n",
    "    \"csm\": ds.ChordSequenceDataset,\n",
    "    \"ktm\": ds.KeyTransitionDataset,\n",
    "    \"ksm\": ds.KeySequenceDataset,\n",
    "}\n",
    "\n",
    "# Load and evaluate validation data\n",
    "for model_name, model in models.items():\n",
    "    logging.info(f\"Evaluating {model_name}\")\n",
    "    if model_name == \"icm\":\n",
    "        logging.info(model.evaluate(pieces))\n",
    "        continue\n",
    "\n",
    "    dataset = dataset_classes[model_name]\n",
    "    h5_path_valid = Path(h5_dir / f\"{dataset.__name__}_valid_seed_{seed}.h5\")\n",
    "    dataset_valid = ds.h5_to_dataset(h5_path_valid, dataset, transform=torch.from_numpy)\n",
    "\n",
    "    logging.info(model.evaluate(dataset_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f\"{i}: {piece.name}\" for i, piece in enumerate(pieces)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose random piece\n",
    "np.random.seed()\n",
    "\n",
    "piece_index = np.random.choice(len(pieces))\n",
    "piece = pieces[piece_index]\n",
    "\n",
    "file_id, piece_name = [string.strip() for string in piece.name.split(':')]\n",
    "file_id = int(file_id)\n",
    "\n",
    "logging.info(f\"Evaluating piece file_id={file_id}: {piece_name}\")\n",
    "\n",
    "joint_model = HarmonicInferenceModel(\n",
    "    models,\n",
    "    min_chord_change_prob=0.15,\n",
    "    max_no_chord_change_prob=0.85,\n",
    ")\n",
    "\n",
    "# Normally, just run joint_model.get_harmony(piece)\n",
    "# Here, we are running it manually\n",
    "joint_model.current_piece = piece\n",
    "\n",
    "# Save caches from piece\n",
    "joint_model.duration_cache = piece.get_duration_cache()\n",
    "joint_model.onset_cache = [vec.onset for vec in piece.get_inputs()] + [\n",
    "    piece.get_inputs()[-1].offset\n",
    "]\n",
    "joint_model.onset_level_cache = [vec.onset_level for vec in piece.get_inputs()] + [\n",
    "    piece.get_inputs()[-1].offset_level\n",
    "]\n",
    "\n",
    "joint_model.debugger = DebugLogger(\n",
    "    joint_model.current_piece,\n",
    "    joint_model.CHORD_OUTPUT_TYPE,\n",
    "    joint_model.KEY_OUTPUT_TYPE,\n",
    "    joint_model.max_chord_branching_factor,\n",
    "    joint_model.max_key_branching_factor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Chord Transition Model\n",
    "chord_change_probs = joint_model.get_chord_change_probs()\n",
    "chord_ranges, chord_range_log_probs = joint_model.get_chord_ranges(chord_change_probs)\n",
    "\n",
    "# Convert range starting points to new starts based on the note offsets\n",
    "chord_change_indices = [start for start, _ in chord_ranges]\n",
    "chord_windows = [\n",
    "    (get_range_start(piece.get_inputs()[start].onset, piece.get_inputs()), end)\n",
    "    for start, end in chord_ranges\n",
    "]\n",
    "\n",
    "joint_model.debugger.debug_chord_change_probs(chord_change_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many ranges are missed?\n",
    "correct_chord_change_indices = piece.get_chord_change_indices()\n",
    "correct_chord_ranges = list(zip(correct_chord_change_indices, list(correct_chord_change_indices[1:]) + [None]))\n",
    "correct_chord_windows = piece.get_chord_ranges()\n",
    "\n",
    "missed = 0\n",
    "for i, correct_range in enumerate(correct_chord_ranges):\n",
    "    if correct_range not in chord_ranges:\n",
    "        print(f\"Chord range {correct_range} not found (chord {i})\")\n",
    "        missed += 1\n",
    "\n",
    "print(f\"Missed {missed} out of {len(correct_chord_change_indices)} ranges\")\n",
    "print(f\"Accuracy (found ranges) = {1 - missed / len(correct_chord_change_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Chord Classification Model on noisy chord ranges\n",
    "chord_classifications = joint_model.get_chord_classifications(chord_windows, chord_change_indices)\n",
    "joint_model.debugger.debug_chord_classifications(chord_ranges, chord_classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Chord Classification Model on true chord ranges\n",
    "true_chord_classifications = joint_model.get_chord_classifications(correct_chord_windows, correct_chord_change_indices)\n",
    "joint_model.debugger.debug_chord_classifications(correct_chord_ranges, true_chord_classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To investigate a specific range\n",
    "range = (1875, 1886)\n",
    "\n",
    "if range in correct_chord_ranges:\n",
    "    ranges = correct_chord_ranges\n",
    "    log_probs = true_chord_classifications\n",
    "elif range in chord_ranges:\n",
    "    ranges = chord_ranges\n",
    "    log_probs = chord_classifications\n",
    "else:\n",
    "    ranges = [range, (0, 2)]\n",
    "    log_probs = joint_model.get_chord_classifications(ranges)\n",
    "\n",
    "index = ranges.index(range)\n",
    "log_prior = log_probs[index]\n",
    "\n",
    "correct_chords = piece.get_chords_within_range(range[0], range[1])\n",
    "correct_notes = piece.get_inputs()[max(range[0] - 10, 0) : range[1]]\n",
    "\n",
    "print(\"Correct chords:\")\n",
    "for chord in correct_chords:\n",
    "    print(f\"    {str(chord)}\")\n",
    "\n",
    "file_chords_df = chords_df.loc[file_id]\n",
    "correct_mcs = set([chord.onset[0] for chord in correct_chords])\n",
    "\n",
    "cols = [\"mc\", \"onset\", \"label\", \"globalkey\", \"localkey\", \"globalkey_is_minor\", \"localkey_is_minor\", \"chord\", \"numeral\", \"figbass\", \"relativeroot\", \"changes\", \"root\", \"bass_note\", \"duration\"]\n",
    "print(file_chords_df.loc[file_chords_df[\"mc\"].isin(correct_mcs), cols])\n",
    "\n",
    "print(\"Notes:\")\n",
    "for note in correct_notes:\n",
    "    print(f\"    {str(note)}\")\n",
    "\n",
    "print(notes_df.loc[file_id].iloc[max(range[0] - 10, 0) : range[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate other models in beam search\n",
    "state = State(\n",
    "    key=piece.get_keys()[0].get_one_hot_index(),\n",
    "    csm_log_prior=joint_model.initial_chord_model.get_prior(\n",
    "        piece.get_keys()[0].relative_mode == KeyMode.MINOR,\n",
    "        log=True,\n",
    "    )\n",
    ")\n",
    "joint_model.debugger.debug_initial_chord_prior(state.csm_log_prior)\n",
    "\n",
    "state = state.chord_transition(\n",
    "    piece.get_chords()[0].get_one_hot_index(\n",
    "        relative=False,\n",
    "        use_inversion=True,\n",
    "        pad=False,\n",
    "    ),\n",
    "    piece.get_chord_change_indices()[1],\n",
    "    0,\n",
    "    joint_model.CHORD_OUTPUT_TYPE,\n",
    "    joint_model.LABELS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pause_on_key_changes = False\n",
    "\n",
    "key_changes_input_indices = piece.get_key_change_input_indices()\n",
    "\n",
    "for chord_index, (start, end) in enumerate(correct_chord_ranges[1:], start=1):\n",
    "    chord = piece.get_chords()[chord_index]\n",
    "    chord_one_hot = chord.get_one_hot_index(relative=False, use_inversion=True, pad=False)\n",
    "    chord_relative_one_hot = chord.get_one_hot_index(relative=True, use_inversion=True, pad=False)\n",
    "\n",
    "    joint_model.run_csm_batched([state])\n",
    "    state = state.chord_transition(\n",
    "        chord_one_hot,\n",
    "        end,\n",
    "        0,\n",
    "        joint_model.CHORD_OUTPUT_TYPE,\n",
    "        joint_model.LABELS,\n",
    "    )\n",
    "\n",
    "    if start in key_changes_input_indices:\n",
    "        if pause_on_key_changes and input() == 'q':\n",
    "            break\n",
    "\n",
    "        # Key change\n",
    "        key_index = key_changes_input_indices.index(start)\n",
    "        prev_key = piece.get_keys()[key_index - 1]\n",
    "        next_key = piece.get_keys()[key_index]\n",
    "\n",
    "        # KTM\n",
    "        key_change_probs = joint_model.get_key_change_probs([state])\n",
    "\n",
    "        # KSM\n",
    "        joint_model.get_key_change_states([state])\n",
    "        state = state.key_transition(\n",
    "            next_key.get_one_hot_index(),\n",
    "            0,\n",
    "            joint_model.KEY_OUTPUT_TYPE,\n",
    "            joint_model.LABELS,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        joint_model.debugger.debug_chord_sequence_priors([state])"
   ]
  }
 ]
}