{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from harmonic_inference.data.corpus_reading import aggregate_annotation_dfs\n",
    "from pathlib import Path\n",
    "\n",
    "ANNOTATIONS_PATH = Path('../corpora/annotations')\n",
    "OUT_DIR = Path('corpus_data')\n",
    "\n",
    "aggregate_annotation_dfs(ANNOTATIONS_PATH, OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harmonic_inference.data.corpus_reading import read_dump\n",
    "from pathlib import Path\n",
    "\n",
    "files_df = read_dump(Path('corpus_data', 'files.tsv'), index_col=0)\n",
    "measures_df = read_dump(Path('corpus_data', 'measures.tsv'))\n",
    "chords_df = read_dump(Path('corpus_data', 'chords.tsv'))\n",
    "notes_df = read_dump(Path('corpus_data', 'notes.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from harmonic_inference.utils import corpus_utils as cu\n",
    "import importlib\n",
    "importlib.reload(cu)\n",
    "import time\n",
    "import logging\n",
    "logging.basicConfig(filename='parsing.log', level=logging.INFO, filemode='w')\n",
    "\n",
    "t = time.time()\n",
    "# Remove measure repeats\n",
    "if isinstance(measures_df.iloc[0].next, tuple):\n",
    "    measures_df = cu.remove_repeats(measures_df, remove_unreachable=True)\n",
    "print(f'Remove measures: {time.time() - t}')\n",
    "\n",
    "t = time.time()\n",
    "# Remove unmatched\n",
    "notes_df = cu.remove_unmatched(notes_df, measures_df)\n",
    "chords_df = cu.remove_unmatched(chords_df, measures_df)\n",
    "chords_df = chords_df.drop(chords_df.loc[(chords_df.numeral == '@none') | chords_df.numeral.isnull()].index)\n",
    "print(f'Remove unmatched: {time.time() - t}')\n",
    "\n",
    "t = time.time()\n",
    "# Add offsets\n",
    "if not all([column in notes_df.columns for column in ['offset_beat', 'offset_mc']]):\n",
    "    notes_df = cu.add_note_offsets(notes_df, measures_df)\n",
    "print(f'Add note offsets: {time.time() - t}')\n",
    "\n",
    "t = time.time()\n",
    "# Merge ties\n",
    "notes_df = cu.merge_ties(notes_df)\n",
    "print(f'Merge ties: {time.time() - t}')\n",
    "\n",
    "t = time.time()\n",
    "# Add chord metrical info\n",
    "chords_df = cu.add_chord_metrical_data(chords_df, measures_df)\n",
    "print(f'Add chords metrical info: {time.time() - t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import harmonic_inference.data.piece as piece\n",
    "import harmonic_inference.utils.harmonic_utils as hu\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename='parsing.log', level=logging.INFO, filemode='w')\n",
    "\n",
    "import importlib\n",
    "importlib.reload(piece)\n",
    "importlib.reload(hu)\n",
    "\n",
    "for i in tqdm(files_df.index):\n",
    "    logging.info(f\"Parsing file id {i}\")\n",
    "    try:\n",
    "        chords = chords_df.loc[i]\n",
    "        notes = notes_df.loc[i]\n",
    "        measures = measures_df.loc[i]\n",
    "    except BaseException as e:\n",
    "        logging.error(f\"Error getting data for index {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        score_piece = piece.ScorePiece(notes, chords, measures)\n",
    "    except BaseException as e:\n",
    "        logging.error(f\"Error parsing index {i}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chords_df.loc[94].loc[chords_df.loc[94].mc == 71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df.loc[102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import harmonic_inference_data as hid\n",
    "import importlib\n",
    "importlib.reload(hid)\n",
    "\n",
    "datasets = {'global': {},\n",
    "            'local': {},\n",
    "            'none': {}}\n",
    "\n",
    "datasets['global']['train'], datasets['global']['valid'], datasets['global']['test'] = hid.get_train_valid_test_splits(\n",
    "    chords_df=chords_df, notes_df=notes_df, measures_df=measures_df, files_df=files_df,\n",
    "    seed=0, h5_directory='data', h5_prefix='globalkey_811split', make_dfs=True, transpose_global=True\n",
    ")\n",
    "\n",
    "datasets['local']['train'], datasets['local']['valid'], datasets['local']['test'] = hid.get_train_valid_test_splits(\n",
    "    chords_df=chords_df, notes_df=notes_df, measures_df=measures_df, files_df=files_df,\n",
    "    seed=0, h5_directory='data', h5_prefix='localkey_811split', make_dfs=True, transpose_local=True\n",
    ")\n",
    "\n",
    "datasets['none']['train'], datasets['none']['valid'], datasets['none']['test'] = hid.get_train_valid_test_splits(\n",
    "    chords_df=chords_df, notes_df=notes_df, measures_df=measures_df, files_df=files_df,\n",
    "    seed=0, h5_directory='data', h5_prefix='811split', make_dfs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import harmonic_inference_models as him\n",
    "import harmonic_utils\n",
    "import importlib\n",
    "importlib.reload(him)\n",
    "from ablation import get_masks_and_names\n",
    "import torch\n",
    "import os\n",
    "\n",
    "masks, mask_names = get_masks_and_names()\n",
    "dir_name = 'results'\n",
    "\n",
    "data = 'local'\n",
    "index = -1\n",
    "prefix = (data + '_') if data != 'none' else ''\n",
    "\n",
    "mask = torch.tensor(masks[index])\n",
    "mask_name = mask_names[index]\n",
    "checkpoint_dir = os.path.join(dir_name, prefix + mask_name)\n",
    "log_file_name = os.path.join(dir_name, prefix + mask_name + '.log')\n",
    "\n",
    "model = him.MusicScoreModel(len(datasets[data]['test'][0]['notes'][0]), len(harmonic_utils.CHORD_TYPES) * 12,\n",
    "                            dropout=0.2, input_mask=mask)\n",
    "\n",
    "print(mask_name)\n",
    "print(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import model_trainer\n",
    "import importlib\n",
    "importlib.reload(model_trainer)\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001)\n",
    "criterion = CrossEntropyLoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "schedule_var = 'valid_loss'\n",
    "\n",
    "trainer = model_trainer.ModelTrainer(model, train_dataset=datasets[data]['train'], valid_dataset=datasets[data]['valid'],\n",
    "                                     test_dataset=datasets[data]['test'], seed=0, num_epochs=100, early_stopping=20,\n",
    "                                     optimizer=optimizer, scheduler=scheduler, schedule_var=schedule_var,\n",
    "                                     criterion=criterion,\n",
    "                                     log_every=1, log_file_name=log_file_name,\n",
    "                                     save_every=10, save_dir=checkpoint_dir, save_prefix='checkpoint',\n",
    "                                     resume=os.path.join(checkpoint_dir, 'best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = model_trainer.ModelTrainer(model, train_dataset=datasets[data]['train'], valid_dataset=datasets[data]['valid'],\n",
    "                                     test_dataset=datasets[data]['test'], seed=0, num_epochs=100, early_stopping=20,\n",
    "                                     optimizer=optimizer, scheduler=scheduler, schedule_var=schedule_var,\n",
    "                                     criterion=criterion,\n",
    "                                     log_every=1, log_file_name=log_file_name,\n",
    "                                     save_every=10, save_dir=checkpoint_dir, save_prefix='checkpoint',\n",
    "                                     resume=os.path.join(checkpoint_dir, 'best.pth.tar'))\n",
    "\n",
    "loss, acc, outputs, labels = trainer.evaluate(valid=False)\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "import harmonic_utils as hu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_strings = hu.get_one_hot_labels()\n",
    "conf_mat = eu.get_conf_mat(labels, outputs)\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(conf_mat, interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(ticks=list(range(len(label_strings))), labels=label_strings, rotation=90, fontsize=10)\n",
    "plt.yticks(ticks=list(range(len(label_strings))), labels=label_strings, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "correct, incorrect = eu.get_correct_and_incorrect_indexes(labels, outputs)\n",
    "print('Correct: ' + str(len(correct)))\n",
    "print('Incorrect: ' + str(len(incorrect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "    \n",
    "eu.print_result(incorrect[0], labels, outputs, limit=10, prob=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "chord, onset_notes, all_notes = eu.get_input_df_rows(incorrect[0], datasets[data]['test'])\n",
    "\n",
    "print(chord)\n",
    "print(\"USED NOTES:\")\n",
    "print(onset_notes)\n",
    "print()\n",
    "print(\"ALL NOTES:\")\n",
    "print(all_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import eval_utils as eu\n",
    "\n",
    "correct_ranks, indexes_by_rank = eu.get_correct_ranks(labels, outputs)\n",
    "    \n",
    "plt.figure(figsize=(30,30))\n",
    "plt.bar(range(len(outputs[0])), [len(indexes) for indexes in indexes_by_rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "import importlib\n",
    "importlib.reload(eu)\n",
    "\n",
    "eval_df = eu.get_eval_df(labels, outputs, datasets[data]['test'])\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ablation\n",
    "import importlib\n",
    "importlib.reload(ablation)\n",
    "\n",
    "dfs = ablation.load_all_ablated_dfs(directory='results', prefix=prefix[:-1] if len(prefix) > 0 else None)\n",
    "_, mask_names = ablation.get_masks_and_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "logs = []\n",
    "for mask_name in mask_names:\n",
    "    logs.append(pd.read_csv(os.path.join(os.path.join('results', prefix + mask_name + '.log'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, log, mask_name in zip(dfs, logs, mask_names):\n",
    "    print(f\"{mask_name} Acc: {100 * df.correct.sum() / len(df)}\")\n",
    "    print(log.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "global_df = eu.load_eval_df('results/global_no_ablation.csv')\n",
    "local_df = eu.load_eval_df('results/local_no_ablation.csv')\n",
    "none_df = eu.load_eval_df('results/no_ablation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_counts = global_df.groupby(['correct_chord'])['correct'].agg(['mean', 'count']).sort_values('count', ascending=False)\n",
    "local_counts = local_df.groupby(['correct_chord'])['correct'].agg(['mean', 'count']).sort_values('count', ascending=False)\n",
    "none_counts = none_df.groupby(['correct_chord'])['correct'].agg(['mean', 'count']).sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.scatter(global_counts['count'], global_counts['mean'], color='red', label='Global key')\n",
    "plt.scatter(local_counts['count'], local_counts['mean'], color='blue', label='Local key')\n",
    "plt.scatter(none_counts['count'], none_counts['mean'], color='yellow', label='No transposition')\n",
    "plt.title('Global key transposed')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}