{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from harmonic_inference.data.corpus_reading import aggregate_annotation_dfs\n",
    "from pathlib import Path\n",
    "\n",
    "ANNOTATIONS_PATH = Path('../corpora/annotations')\n",
    "OUT_DIR = Path('corpus_data')\n",
    "\n",
    "aggregate_annotation_dfs(ANNOTATIONS_PATH, OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harmonic_inference.data.corpus_reading import read_dump\n",
    "from pathlib import Path\n",
    "\n",
    "files_df = read_dump(Path('corpus_data', 'files.tsv'), index_col=0)\n",
    "measures_df = read_dump(Path('corpus_data', 'measures.tsv'))\n",
    "chords_df = read_dump(Path('corpus_data', 'chords.tsv'), low_memory=False)\n",
    "notes_df = read_dump(Path('corpus_data', 'notes.tsv'))\n",
    "\n",
    "files_df_orig = files_df\n",
    "measures_df_orig = measures_df\n",
    "notes_df_orig = notes_df\n",
    "chords_df_orig = chords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from harmonic_inference.utils import corpus_utils as cu\n",
    "import importlib\n",
    "importlib.reload(cu)\n",
    "import time\n",
    "import logging\n",
    "logging.basicConfig(filename='parsing.log', level=logging.INFO, filemode='w')\n",
    "\n",
    "t = time.time()\n",
    "# Remove measure repeats\n",
    "if isinstance(measures_df.iloc[0].next, tuple):\n",
    "    measures_df = cu.remove_repeats(measures_df, remove_unreachable=True)\n",
    "print(f'Remove measures: {time.time() - t}')\n",
    "\n",
    "t = time.time()\n",
    "# Remove unmatched\n",
    "notes_df = cu.remove_unmatched(notes_df, measures_df)\n",
    "chords_df = cu.remove_unmatched(chords_df, measures_df)\n",
    "chords_df = chords_df.drop(chords_df.loc[(chords_df.numeral == '@none') | chords_df.numeral.isnull()].index)\n",
    "print(f'Remove unmatched: {time.time() - t}')\n",
    "\n",
    "t = time.time()\n",
    "# Add offsets\n",
    "if not all([column in notes_df.columns for column in ['offset_beat', 'offset_mc']]):\n",
    "    notes_df = cu.add_note_offsets(notes_df, measures_df)\n",
    "print(f'Add note offsets: {time.time() - t}')\n",
    "\n",
    "t = time.time()\n",
    "# Merge ties\n",
    "notes_df = cu.merge_ties(notes_df)\n",
    "print(f'Merge ties: {time.time() - t}')\n",
    "\n",
    "t = time.time()\n",
    "# Add chord metrical info\n",
    "chords_df = cu.add_chord_metrical_data(chords_df, measures_df)\n",
    "print(f'Add chords metrical info: {time.time() - t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import harmonic_inference.data.datasets as ds\n",
    "\n",
    "import importlib\n",
    "importlib.reload(ds)\n",
    "\n",
    "dataset_splits = ds.get_dataset_splits(\n",
    "    files_df,\n",
    "    measures_df,\n",
    "    chords_df,\n",
    "    notes_df,\n",
    "    [ds.ChordTransitionDataset, ds.ChordClassificationDataset],\n",
    "    splits=[0.8, 0.1, 0.1],\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "import harmonic_utils as hu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_strings = hu.get_one_hot_labels()\n",
    "conf_mat = eu.get_conf_mat(labels, outputs)\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(conf_mat, interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(ticks=list(range(len(label_strings))), labels=label_strings, rotation=90, fontsize=10)\n",
    "plt.yticks(ticks=list(range(len(label_strings))), labels=label_strings, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "correct, incorrect = eu.get_correct_and_incorrect_indexes(labels, outputs)\n",
    "print('Correct: ' + str(len(correct)))\n",
    "print('Incorrect: ' + str(len(incorrect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "    \n",
    "eu.print_result(incorrect[0], labels, outputs, limit=10, prob=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "chord, onset_notes, all_notes = eu.get_input_df_rows(incorrect[0], datasets[data]['test'])\n",
    "\n",
    "print(chord)\n",
    "print(\"USED NOTES:\")\n",
    "print(onset_notes)\n",
    "print()\n",
    "print(\"ALL NOTES:\")\n",
    "print(all_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import eval_utils as eu\n",
    "\n",
    "correct_ranks, indexes_by_rank = eu.get_correct_ranks(labels, outputs)\n",
    "    \n",
    "plt.figure(figsize=(30,30))\n",
    "plt.bar(range(len(outputs[0])), [len(indexes) for indexes in indexes_by_rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "import importlib\n",
    "importlib.reload(eu)\n",
    "\n",
    "eval_df = eu.get_eval_df(labels, outputs, datasets[data]['test'])\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ablation\n",
    "import importlib\n",
    "importlib.reload(ablation)\n",
    "\n",
    "dfs = ablation.load_all_ablated_dfs(directory='results', prefix=prefix[:-1] if len(prefix) > 0 else None)\n",
    "_, mask_names = ablation.get_masks_and_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "logs = []\n",
    "for mask_name in mask_names:\n",
    "    logs.append(pd.read_csv(os.path.join(os.path.join('results', prefix + mask_name + '.log'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, log, mask_name in zip(dfs, logs, mask_names):\n",
    "    print(f\"{mask_name} Acc: {100 * df.correct.sum() / len(df)}\")\n",
    "    print(log.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "global_df = eu.load_eval_df('results/global_no_ablation.csv')\n",
    "local_df = eu.load_eval_df('results/local_no_ablation.csv')\n",
    "none_df = eu.load_eval_df('results/no_ablation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_counts = global_df.groupby(['correct_chord'])['correct'].agg(['mean', 'count']).sort_values('count', ascending=False)\n",
    "local_counts = local_df.groupby(['correct_chord'])['correct'].agg(['mean', 'count']).sort_values('count', ascending=False)\n",
    "none_counts = none_df.groupby(['correct_chord'])['correct'].agg(['mean', 'count']).sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.scatter(global_counts['count'], global_counts['mean'], color='red', label='Global key')\n",
    "plt.scatter(local_counts['count'], local_counts['mean'], color='blue', label='Local key')\n",
    "plt.scatter(none_counts['count'], none_counts['mean'], color='yellow', label='No transposition')\n",
    "plt.title('Global key transposed')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}