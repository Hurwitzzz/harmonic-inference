{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To re-create corpus_data directory\n",
    "# from harmonic_inference.data.corpus_reading import aggregate_annotation_dfs\n",
    "# from pathlib import Path\n",
    "\n",
    "# ANNOTATIONS_PATH = Path('../corpora/annotations')\n",
    "# OUT_DIR = Path('corpus_data')\n",
    "\n",
    "# aggregate_annotation_dfs(ANNOTATIONS_PATH, OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from harmonic_inference.data.corpus_reading import load_clean_corpus_dfs\n",
    "\n",
    "files_df, measures_df, chords_df, notes_df = load_clean_corpus_dfs('corpus_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Training of initial chord prior model\"\"\"\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from harmonic_inference.data.piece import Chord\n",
    "from harmonic_inference.data.data_types import PitchType, KeyMode\n",
    "\n",
    "\n",
    "initial_chords = chords_df.loc[chords_df.index.get_level_values(\"chord_id\") == 0]\n",
    "chords = [\n",
    "    Chord.from_series(row, measures_df.loc[file_id], PitchType.TPC)\n",
    "    for (file_id, chord_id), row in initial_chords.iterrows()\n",
    "]\n",
    "\n",
    "major_key_chords = []\n",
    "minor_key_chords = []\n",
    "\n",
    "one_hot_length = chords[0].get_chord_vector_length(\n",
    "    PitchType.TPC,\n",
    "    one_hot=True,\n",
    "    relative=True,\n",
    "    use_inversions=True,\n",
    ")\n",
    "norm_factor = 1 / one_hot_length\n",
    "major_key_chords_one_hots = np.ones(one_hot_length) * norm_factor\n",
    "minor_key_chords_one_hots = np.ones(one_hot_length) * norm_factor\n",
    "\n",
    "for chord in chords:\n",
    "    one_hot_index = chord.get_one_hot_index(relative=True, use_inversion=True)\n",
    "\n",
    "    if chord.key_mode == KeyMode.MAJOR:\n",
    "        major_key_chords.append(chord)\n",
    "        major_key_chords_one_hots[one_hot_index] += 1\n",
    "    else:\n",
    "        minor_key_chords.append(chord)\n",
    "        minor_key_chords_one_hots[one_hot_index] += 1\n",
    "\n",
    "# Normalize\n",
    "major_key_chords_one_hots /= np.sum(major_key_chords_one_hots)\n",
    "minor_key_chords_one_hots /= np.sum(minor_key_chords_one_hots)\n",
    "\n",
    "with open(Path(\"checkpoints\", \"initial_chord_prior.json\"), \"w\") as json_file:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"pitch_type\": str(PitchType.TPC).split(\".\")[1],\n",
    "            \"use_inversions\": True,\n",
    "            \"major\": list(major_key_chords_one_hots),\n",
    "            \"minor\": list(minor_key_chords_one_hots),\n",
    "        },\n",
    "        json_file,\n",
    "        indent=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import harmonic_inference.data.datasets as ds\n",
    "\n",
    "dataset_classes = [ds.ChordTransitionDataset, ds.ChordClassificationDataset]\n",
    "\n",
    "dataset_splits = ds.get_dataset_splits(\n",
    "    files_df,\n",
    "    measures_df,\n",
    "    chords_df,\n",
    "    notes_df,\n",
    "    dataset_classes,\n",
    "    splits=[0.8, 0.1, 0.1],\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data out to h5 files\n",
    "for i1, data_type in enumerate(dataset_classes):\n",
    "    for i2, split in enumerate(['train', 'valid', 'test']):\n",
    "        h5_path = Path('h5_data', f'{data_type.__name__}_{split}_seed_{seed}.h5')\n",
    "        dataset_splits[i1][i2].to_h5(Path(h5_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "import harmonic_utils as hu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_strings = hu.get_one_hot_labels()\n",
    "conf_mat = eu.get_conf_mat(labels, outputs)\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(conf_mat, interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(ticks=list(range(len(label_strings))), labels=label_strings, rotation=90, fontsize=10)\n",
    "plt.yticks(ticks=list(range(len(label_strings))), labels=label_strings, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "correct, incorrect = eu.get_correct_and_incorrect_indexes(labels, outputs)\n",
    "print('Correct: ' + str(len(correct)))\n",
    "print('Incorrect: ' + str(len(incorrect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "    \n",
    "eu.print_result(incorrect[0], labels, outputs, limit=10, prob=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "chord, onset_notes, all_notes = eu.get_input_df_rows(incorrect[0], datasets[data]['test'])\n",
    "\n",
    "print(chord)\n",
    "print(\"USED NOTES:\")\n",
    "print(onset_notes)\n",
    "print()\n",
    "print(\"ALL NOTES:\")\n",
    "print(all_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import eval_utils as eu\n",
    "\n",
    "correct_ranks, indexes_by_rank = eu.get_correct_ranks(labels, outputs)\n",
    "    \n",
    "plt.figure(figsize=(30,30))\n",
    "plt.bar(range(len(outputs[0])), [len(indexes) for indexes in indexes_by_rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "import importlib\n",
    "importlib.reload(eu)\n",
    "\n",
    "eval_df = eu.get_eval_df(labels, outputs, datasets[data]['test'])\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ablation\n",
    "import importlib\n",
    "importlib.reload(ablation)\n",
    "\n",
    "dfs = ablation.load_all_ablated_dfs(directory='results', prefix=prefix[:-1] if len(prefix) > 0 else None)\n",
    "_, mask_names = ablation.get_masks_and_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "logs = []\n",
    "for mask_name in mask_names:\n",
    "    logs.append(pd.read_csv(os.path.join(os.path.join('results', prefix + mask_name + '.log'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, log, mask_name in zip(dfs, logs, mask_names):\n",
    "    print(f\"{mask_name} Acc: {100 * df.correct.sum() / len(df)}\")\n",
    "    print(log.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "global_df = eu.load_eval_df('results/global_no_ablation.csv')\n",
    "local_df = eu.load_eval_df('results/local_no_ablation.csv')\n",
    "none_df = eu.load_eval_df('results/no_ablation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_counts = global_df.groupby(['correct_chord'])['correct'].agg(['mean', 'count']).sort_values('count', ascending=False)\n",
    "local_counts = local_df.groupby(['correct_chord'])['correct'].agg(['mean', 'count']).sort_values('count', ascending=False)\n",
    "none_counts = none_df.groupby(['correct_chord'])['correct'].agg(['mean', 'count']).sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.scatter(global_counts['count'], global_counts['mean'], color='red', label='Global key')\n",
    "plt.scatter(local_counts['count'], local_counts['mean'], color='blue', label='Local key')\n",
    "plt.scatter(none_counts['count'], none_counts['mean'], color='yellow', label='No transposition')\n",
    "plt.title('Global key transposed')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Start of baseline evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "from fractions import Fraction\n",
    "from bisect import bisect\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from harmonic_inference.utils import eval_utils as eu\n",
    "from harmonic_inference.utils import harmonic_utils as hu\n",
    "from harmonic_inference.data.data_types import ChordType, PitchType, KeyMode, TRIAD_REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for file in glob(\"outputs/baseline/*.csv\"):\n",
    "    file_path = Path(file)\n",
    "    results[file_path.name] = pd.read_csv(file, header=None, names=['on', 'off', 'key', 'degree', 'type', 'inv'])\n",
    "\n",
    "    # Output is in quarter notes, labels are in whole notes\n",
    "    results[file_path.name][\"on\"] /= 4\n",
    "    results[file_path.name][\"off\"] /= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = set()\n",
    "degrees = set()\n",
    "types = set()\n",
    "inversions = set()\n",
    "\n",
    "for df in results.values():\n",
    "    for k in df['key'].unique():\n",
    "        keys.add(k)\n",
    "    for d in df['degree'].unique():\n",
    "        degrees.add(d)\n",
    "    for t in df['type'].unique():\n",
    "        types.add(t)\n",
    "    for i in df['inv'].unique():\n",
    "        inversions.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_to_tonic_mode(key: str, pitch_type: PitchType = PitchType.TPC) -> Tuple[int, KeyMode]:\n",
    "    key = key.replace('-', 'b')\n",
    "    key = key.replace('+', '#')\n",
    "    \n",
    "    tonic = hu.get_pitch_from_string(key, pitch_type)\n",
    "    mode = KeyMode.MAJOR if key[0].isupper() else KeyMode.MINOR\n",
    "    \n",
    "    return tonic, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_to_chord_type(type_str: str) -> ChordType:\n",
    "    return {\n",
    "        'D7': ChordType.MAJ_MIN7,\n",
    "        'M': ChordType.MAJOR,\n",
    "        'd': ChordType.DIMINISHED,\n",
    "        'd7': ChordType.DIM7,\n",
    "        'm': ChordType.MINOR,\n",
    "        'm7': ChordType.MIN_MIN7,\n",
    "        'Gr+6': ChordType.DIM7,\n",
    "        'h7': ChordType.HALF_DIM7,\n",
    "    }[type_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_tonic_and_mode(\n",
    "    degree_str: str, tonic: int, mode: KeyMode, pitch_type: PitchType = PitchType.TPC\n",
    ") -> Tuple[int, int, KeyMode]:\n",
    "    if isinstance(degree_str, int):\n",
    "        degree_str = str(degree_str)\n",
    "        \n",
    "    degree_str = degree_str.replace('-', 'b')\n",
    "    degree_str = degree_str.replace('+', '#')\n",
    "    \n",
    "    if '/' in degree_str:\n",
    "        key, degree_str = degree_str.split('/')\n",
    "        \n",
    "        relative_transposition = hu.get_interval_from_scale_degree(key, False, mode, pitch_type=pitch_type)\n",
    "        tonic = hu.transpose_pitch(tonic, relative_transposition, pitch_type=pitch_type)\n",
    "        \n",
    "        if key in ['5']:\n",
    "            mode = KeyMode.MAJOR\n",
    "        elif key in ['7']:\n",
    "            mode = KeyMode.MINOR\n",
    "        elif key in ['1']:\n",
    "            mode = mode\n",
    "            \n",
    "    degree_interval = hu.get_interval_from_scale_degree(degree_str, False, mode, pitch_type=pitch_type)\n",
    "    root = hu.transpose_pitch(tonic, degree_interval, pitch_type=pitch_type)\n",
    "    \n",
    "    return root, tonic, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(key: str, degree: str, type_str: str, inv: str) -> Tuple[int, ChordType, int, int, KeyMode]:\n",
    "    inv = int(inv)\n",
    "    chord_type = type_to_chord_type(type_str)\n",
    "    \n",
    "    tonic, mode = key_to_tonic_mode(key)\n",
    "    root, tonic, mode = get_root_tonic_and_mode(degree, tonic, mode)\n",
    "    \n",
    "    return root, chord_type, inv, tonic, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in results.values():\n",
    "    roots = []\n",
    "    chord_types = []\n",
    "    invs = []\n",
    "    tonics = []\n",
    "    modes = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        root, chord_type, inv, tonic, mode = get_all(row['key'], row['degree'], row['type'], row['inv'])\n",
    "        roots.append(root)\n",
    "        chord_types.append(chord_type)\n",
    "        invs.append(inv)\n",
    "        tonics.append(tonic)\n",
    "        modes.append(mode)\n",
    "        \n",
    "    df[\"root_tpc\"] = roots\n",
    "    df[\"chord_type\"] = chord_types\n",
    "    df[\"inversion\"] = invs\n",
    "    df[\"tonic\"] = tonics\n",
    "    df[\"mode\"] = modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_df(filename: str) -> pd.DataFrame:\n",
    "    filename = filename[:-21] + \"results.tsv\"\n",
    "    file = glob(f'outputs/results-csm-1-kse-75/**/{filename}', recursive=True)[0]\n",
    "    \n",
    "    return pd.read_csv(file, sep='\\t', index_col=0, converters={'duration': Fraction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_at_onset(df, onset):\n",
    "    index = min(bisect(list(df['off']), float(onset)), len(df) - 1)\n",
    "    return df.iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_df(key, df):\n",
    "    label_df = get_label_df(key)\n",
    "    chord_accs = []\n",
    "    triad_accs = []\n",
    "    seventh_accs = []\n",
    "    key_accs = []\n",
    "    full_accs = []\n",
    "    \n",
    "    onset = 0\n",
    "    for _, label_row in label_df.iterrows():\n",
    "        est_row = get_row_at_onset(df, onset)\n",
    "        onset += label_row['duration']\n",
    "        \n",
    "        tonic_str = label_row['gt_key'].split(':')[0]\n",
    "        if '/' in tonic_str:\n",
    "            tonic_str = tonic_str.split('/')[0]\n",
    "            \n",
    "        gt_tonic = hu.get_pitch_from_string(tonic_str, pitch_type=PitchType.TPC)\n",
    "        gt_mode = KeyMode.MAJOR if label_row['gt_key'][0].isupper() else KeyMode.MINOR\n",
    "        \n",
    "        gt_chord = label_row['gt_chord']\n",
    "        gt_inv = int(gt_chord[-1])\n",
    "        root_str = gt_chord.split(':')[0]\n",
    "        if '/' in root_str:\n",
    "            root_str = root_str.split('/')[0]\n",
    "        gt_root = hu.get_pitch_from_string(root_str, pitch_type=PitchType.TPC)\n",
    "        gt_chord_type = hu.get_chord_type_from_string(gt_chord.split(':')[1].split(',')[0])\n",
    "        \n",
    "        chord_dist = eu.get_chord_distance(\n",
    "            gt_root,\n",
    "            gt_chord_type,\n",
    "            gt_inv,\n",
    "            est_row['root_tpc'],\n",
    "            est_row['chord_type'],\n",
    "            est_row['inversion'],\n",
    "        )\n",
    "        chord_accs.append(1 - chord_dist)\n",
    "        \n",
    "        triad_dist = eu.get_chord_distance(\n",
    "            gt_root,\n",
    "            gt_chord_type,\n",
    "            0,\n",
    "            est_row['root_tpc'],\n",
    "            est_row['chord_type'],\n",
    "            0,\n",
    "            reduction=TRIAD_REDUCTION\n",
    "        )\n",
    "        triad_accs.append(1 - triad_dist)\n",
    "        \n",
    "        seventh_dist = eu.get_chord_distance(\n",
    "            gt_root,\n",
    "            gt_chord_type,\n",
    "            0,\n",
    "            est_row['root_tpc'],\n",
    "            est_row['chord_type'],\n",
    "            0,\n",
    "        )\n",
    "        seventh_accs.append(1 - seventh_dist)\n",
    "        \n",
    "        key_dist = eu.get_key_distance(\n",
    "            gt_tonic,\n",
    "            gt_mode,\n",
    "            est_row['tonic'],\n",
    "            est_row['mode'],\n",
    "        )\n",
    "        key_accs.append(1 - key_dist)\n",
    "        \n",
    "        full_accs.append(1 if chord_dist + key_dist == 0 else 0)\n",
    "        \n",
    "    chord_acc = float(np.average(chord_accs, weights=label_df['duration']))\n",
    "    key_acc = float(np.average(key_accs, weights=label_df['duration']))\n",
    "    full_acc = float(np.average(full_accs, weights=label_df['duration']))\n",
    "    triad_acc = float(np.average(triad_accs, weights=label_df['duration']))\n",
    "    seventh_acc = float(np.average(seventh_accs, weights=label_df['duration']))\n",
    "    \n",
    "    return {\n",
    "        \"Triad\": triad_acc,\n",
    "        \"Seventh\": seventh_acc,\n",
    "        \"Chord\": chord_acc,\n",
    "        \"Key\": key_acc,\n",
    "        \"Full\": full_acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_vals = {}\n",
    "import re\n",
    "\n",
    "for key, df in results.items():\n",
    "    # Beethoven match\n",
    "    if not re.match(r\"[0-9][0-9]-[0-9]_inf\", key):\n",
    "        continue\n",
    "    \n",
    "    print(key)\n",
    "    for acc, val in evaluate_df(key, df).items():\n",
    "        if acc not in results_vals:\n",
    "            results_vals[acc] = []\n",
    "        results_vals[acc].append(val)\n",
    "        print(f\"    {acc}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acc, val_list in results_vals.items():\n",
    "    print(f\"{acc}: {sum(val_list) / len(val_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from fractions import Fraction\n",
    "\n",
    "import pandas as pd\n",
    "from music21.converter import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m21_score = parse(Path(\"../functional-harmony/data/BPS/scores/bps_01_01.mxl\"))\n",
    "m21_score = m21_score.flattenParts()\n",
    "m21_score = m21_score.stripTies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in m21_score.recurse().notes:\n",
    "    if note.isChord:\n",
    "        chord = note\n",
    "        print(\"Chord\")\n",
    "        for note in chord.notes:\n",
    "            print(note.pitch.name, note.pitch.octave, chord.duration.quarterLength, chord.offset, chord.measureNumber, note.tie, chord.tie)\n",
    "        print(\"End Chord\")\n",
    "    else:\n",
    "        print(note.offset\n",
    "        print(note.pitch.name, note.pitch.octave, note.duration.quarterLength, note.offset, note.measureNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for offset, measure in m21_score.measureOffsetMap().items():\r\n",
    "    print(offset, measure[0].timeSignature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "import harmonic_inference.data.piece as piece\n",
    "importlib.reload(piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes, measures_df = piece.get_score_piece_from_music_xml(Path(\"../functional-harmony/data/BPS/scores/bps_01_01.mxl\"), \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df[40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(note for note in notes if note.onset[0] in [48, 49])"
   ]
  },
  {
   "source": [
    "# Test loading funcional-harmony data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import harmonic_inference.data.piece as piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in glob(\"../functional-harmony/data/**/*.mxl\", recursive=True):\n",
    "    music_xml_path = Path(file_path)\n",
    "    label_csv_path = music_xml_path.parent.parent / \"chords\" / Path(str(music_xml_path.stem) + \".csv\")\n",
    "\n",
    "    score = piece.get_score_piece_from_music_xml(music_xml_path, label_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python379jvsc74a57bd0a191b7ca072ee042befe415e9c73f471d3b801044783c4feae37afcfb1965ba9",
   "display_name": "Python 3.7.9 64-bit ('harmony': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}