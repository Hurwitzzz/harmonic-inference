{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To re-create corpus_data directory\n",
    "# from harmonic_inference.data.corpus_reading import aggregate_annotation_dfs\n",
    "# from pathlib import Path\n",
    "\n",
    "# ANNOTATIONS_PATH = Path('../platti_sonatas')\n",
    "# OUT_DIR = Path('corpus_data-platti')\n",
    "\n",
    "# aggregate_annotation_dfs(ANNOTATIONS_PATH, OUT_DIR, notes_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from harmonic_inference.data.corpus_reading import load_clean_corpus_dfs\n",
    "\n",
    "files_df, measures_df, chords_df, notes_df = load_clean_corpus_dfs('corpus_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def is_major(chord_row):\n",
    "    if pd.isna(chord_row[\"relativeroot\"]):\n",
    "        return not chord_row[\"localkey_is_minor\"]\n",
    "    return chord_row[\"relativeroot\"].split(\"/\")[0][-1].isupper()\n",
    "\n",
    "chords_df = chords_df.loc[~chords_df[\"globalkey\"].isna()]\n",
    "    \n",
    "\n",
    "chords_df.loc[:, \"is_major\"] = chords_df.apply(is_major, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df.loc[chords_df[\"is_major\"], [\"numeral\", \"chord_type\"]]\n",
    "chords_df.loc[:, [\"num:type\"]] = chords_df[\"numeral\"] + \":\" + chords_df[\"chord_type\"]\n",
    "chords_df.loc[chords_df[\"is_major\"], \"num:type\"].value_counts().to_csv(\"major.tsv\", sep=\"\\t\")\n",
    "chords_df.loc[~chords_df[\"is_major\"], \"num:type\"].value_counts().to_csv(\"minor.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df.loc[(~chords_df[\"relativeroot\"].shift(1).isna()) | (~chords_df[\"relativeroot\"].isna()), [\"relativeroot\", \"numeral\", \"chord_type\"]].to_csv(\"relative.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_df.loc[(chords_df[\"chord_type\"] == \"Ger\") & chords_df[\"is_major\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Training of initial chord prior model\"\"\"\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from harmonic_inference.data.piece import Chord\n",
    "from harmonic_inference.data.data_types import PitchType, KeyMode\n",
    "\n",
    "\n",
    "initial_chords = chords_df.loc[chords_df.index.get_level_values(\"chord_id\") == 0]\n",
    "chords = [\n",
    "    Chord.from_series(row, measures_df.loc[file_id], PitchType.TPC)\n",
    "    for (file_id, chord_id), row in initial_chords.iterrows()\n",
    "]\n",
    "\n",
    "major_key_chords = []\n",
    "minor_key_chords = []\n",
    "\n",
    "one_hot_length = chords[0].get_chord_vector_length(\n",
    "    PitchType.TPC,\n",
    "    one_hot=True,\n",
    "    relative=True,\n",
    "    use_inversions=True,\n",
    ")\n",
    "norm_factor = 1 / one_hot_length\n",
    "major_key_chords_one_hots = np.ones(one_hot_length) * norm_factor\n",
    "minor_key_chords_one_hots = np.ones(one_hot_length) * norm_factor\n",
    "\n",
    "for chord in chords:\n",
    "    one_hot_index = chord.get_one_hot_index(relative=True, use_inversion=True)\n",
    "\n",
    "    if chord.key_mode == KeyMode.MAJOR:\n",
    "        major_key_chords.append(chord)\n",
    "        major_key_chords_one_hots[one_hot_index] += 1\n",
    "    else:\n",
    "        minor_key_chords.append(chord)\n",
    "        minor_key_chords_one_hots[one_hot_index] += 1\n",
    "\n",
    "# Normalize\n",
    "major_key_chords_one_hots /= np.sum(major_key_chords_one_hots)\n",
    "minor_key_chords_one_hots /= np.sum(minor_key_chords_one_hots)\n",
    "\n",
    "with open(Path(\"checkpoints\", \"initial_chord_prior.json\"), \"w\") as json_file:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"pitch_type\": str(PitchType.TPC).split(\".\")[1],\n",
    "            \"use_inversions\": True,\n",
    "            \"major\": list(major_key_chords_one_hots),\n",
    "            \"minor\": list(minor_key_chords_one_hots),\n",
    "        },\n",
    "        json_file,\n",
    "        indent=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import harmonic_inference.data.datasets as ds\n",
    "\n",
    "dataset_classes = [ds.ChordTransitionDataset, ds.ChordClassificationDataset]\n",
    "\n",
    "dataset_splits = ds.get_dataset_splits(\n",
    "    files_df,\n",
    "    measures_df,\n",
    "    chords_df,\n",
    "    notes_df,\n",
    "    dataset_classes,\n",
    "    splits=[0.8, 0.1, 0.1],\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data out to h5 files\n",
    "for i1, data_type in enumerate(dataset_classes):\n",
    "    for i2, split in enumerate(['train', 'valid', 'test']):\n",
    "        h5_path = Path('h5_data', f'{data_type.__name__}_{split}_seed_{seed}.h5')\n",
    "        dataset_splits[i1][i2].to_h5(Path(h5_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "import harmonic_utils as hu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_strings = hu.get_one_hot_labels()\n",
    "conf_mat = eu.get_conf_mat(labels, outputs)\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(conf_mat, interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(ticks=list(range(len(label_strings))), labels=label_strings, rotation=90, fontsize=10)\n",
    "plt.yticks(ticks=list(range(len(label_strings))), labels=label_strings, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "correct, incorrect = eu.get_correct_and_incorrect_indexes(labels, outputs)\n",
    "print('Correct: ' + str(len(correct)))\n",
    "print('Incorrect: ' + str(len(incorrect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "    \n",
    "eu.print_result(incorrect[0], labels, outputs, limit=10, prob=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "chord, onset_notes, all_notes = eu.get_input_df_rows(incorrect[0], datasets[data]['test'])\n",
    "\n",
    "print(chord)\n",
    "print(\"USED NOTES:\")\n",
    "print(onset_notes)\n",
    "print()\n",
    "print(\"ALL NOTES:\")\n",
    "print(all_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import eval_utils as eu\n",
    "\n",
    "correct_ranks, indexes_by_rank = eu.get_correct_ranks(labels, outputs)\n",
    "    \n",
    "plt.figure(figsize=(30,30))\n",
    "plt.bar(range(len(outputs[0])), [len(indexes) for indexes in indexes_by_rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "import importlib\n",
    "importlib.reload(eu)\n",
    "\n",
    "eval_df = eu.get_eval_df(labels, outputs, datasets[data]['test'])\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ablation\n",
    "import importlib\n",
    "importlib.reload(ablation)\n",
    "\n",
    "dfs = ablation.load_all_ablated_dfs(directory='results', prefix=prefix[:-1] if len(prefix) > 0 else None)\n",
    "_, mask_names = ablation.get_masks_and_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "logs = []\n",
    "for mask_name in mask_names:\n",
    "    logs.append(pd.read_csv(os.path.join(os.path.join('results', prefix + mask_name + '.log'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, log, mask_name in zip(dfs, logs, mask_names):\n",
    "    print(f\"{mask_name} Acc: {100 * df.correct.sum() / len(df)}\")\n",
    "    print(log.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "global_df = eu.load_eval_df('results/global_no_ablation.csv')\n",
    "local_df = eu.load_eval_df('results/local_no_ablation.csv')\n",
    "none_df = eu.load_eval_df('results/no_ablation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_counts = global_df.groupby(['correct_chord'])['correct'].agg(['mean', 'count']).sort_values('count', ascending=False)\n",
    "local_counts = local_df.groupby(['correct_chord'])['correct'].agg(['mean', 'count']).sort_values('count', ascending=False)\n",
    "none_counts = none_df.groupby(['correct_chord'])['correct'].agg(['mean', 'count']).sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.scatter(global_counts['count'], global_counts['mean'], color='red', label='Global key')\n",
    "plt.scatter(local_counts['count'], local_counts['mean'], color='blue', label='Local key')\n",
    "plt.scatter(none_counts['count'], none_counts['mean'], color='yellow', label='No transposition')\n",
    "plt.title('Global key transposed')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of baseline evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "from fractions import Fraction\n",
    "from bisect import bisect\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from harmonic_inference.utils import eval_utils as eu\n",
    "from harmonic_inference.utils import harmonic_utils as hu\n",
    "from harmonic_inference.data.data_types import ChordType, PitchType, KeyMode, TRIAD_REDUCTION, ALL_ONE_TYPE_REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for file in glob(\"baseline/*.csv\"):\n",
    "    file_path = Path(file)\n",
    "    results[file_path.name] = pd.read_csv(file, header=None, names=['on', 'off', 'key', 'degree', 'type', 'inv'])\n",
    "\n",
    "    # Output is in quarter notes, labels are in whole notes\n",
    "    results[file_path.name][\"on\"] /= 4\n",
    "    results[file_path.name][\"off\"] /= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = set()\n",
    "degrees = set()\n",
    "types = set()\n",
    "inversions = set()\n",
    "\n",
    "for df in results.values():\n",
    "    for k in df['key'].unique():\n",
    "        keys.add(k)\n",
    "    for d in df['degree'].unique():\n",
    "        degrees.add(d)\n",
    "    for t in df['type'].unique():\n",
    "        types.add(t)\n",
    "    for i in df['inv'].unique():\n",
    "        inversions.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_to_tonic_mode(key: str, pitch_type: PitchType = PitchType.TPC) -> Tuple[int, KeyMode]:\n",
    "    key = key.replace('-', 'b')\n",
    "    key = key.replace('+', '#')\n",
    "    \n",
    "    tonic = hu.get_pitch_from_string(key, pitch_type)\n",
    "    mode = KeyMode.MAJOR if key[0].isupper() else KeyMode.MINOR\n",
    "    \n",
    "    return tonic, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_to_chord_type(type_str: str) -> ChordType:\n",
    "    return {\n",
    "        'D7': ChordType.MAJ_MIN7,\n",
    "        'M': ChordType.MAJOR,\n",
    "        'd': ChordType.DIMINISHED,\n",
    "        'd7': ChordType.DIM7,\n",
    "        'm': ChordType.MINOR,\n",
    "        'm7': ChordType.MIN_MIN7,\n",
    "        'Gr+6': ChordType.DIM7,\n",
    "        'h7': ChordType.HALF_DIM7,\n",
    "    }[type_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_tonic_and_mode(\n",
    "    degree_str: str, tonic: int, mode: KeyMode, pitch_type: PitchType = PitchType.TPC\n",
    ") -> Tuple[int, int, KeyMode]:\n",
    "    if isinstance(degree_str, int):\n",
    "        degree_str = str(degree_str)\n",
    "        \n",
    "    degree_str = degree_str.replace('-', 'b')\n",
    "    degree_str = degree_str.replace('+', '#')\n",
    "    \n",
    "    if '/' in degree_str:\n",
    "        key, degree_str = degree_str.split('/')\n",
    "        \n",
    "        relative_transposition = hu.get_interval_from_scale_degree(key, False, mode, pitch_type=pitch_type)\n",
    "        tonic = hu.transpose_pitch(tonic, relative_transposition, pitch_type=pitch_type)\n",
    "        \n",
    "        if key in ['5']:\n",
    "            mode = KeyMode.MAJOR\n",
    "        elif key in ['7']:\n",
    "            mode = KeyMode.MINOR\n",
    "        elif key in ['1']:\n",
    "            mode = mode\n",
    "            \n",
    "    degree_interval = hu.get_interval_from_scale_degree(degree_str, False, mode, pitch_type=pitch_type)\n",
    "    root = hu.transpose_pitch(tonic, degree_interval, pitch_type=pitch_type)\n",
    "    \n",
    "    return root, tonic, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(key: str, degree: str, type_str: str, inv: str) -> Tuple[int, ChordType, int, int, KeyMode]:\n",
    "    inv = int(inv)\n",
    "    chord_type = type_to_chord_type(type_str)\n",
    "    \n",
    "    tonic, mode = key_to_tonic_mode(key)\n",
    "    root, tonic, mode = get_root_tonic_and_mode(degree, tonic, mode)\n",
    "    \n",
    "    return root, chord_type, inv, tonic, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in results.values():\n",
    "    roots = []\n",
    "    chord_types = []\n",
    "    invs = []\n",
    "    tonics = []\n",
    "    modes = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        root, chord_type, inv, tonic, mode = get_all(row['key'], row['degree'], row['type'], row['inv'])\n",
    "        roots.append(root)\n",
    "        chord_types.append(chord_type)\n",
    "        invs.append(inv)\n",
    "        tonics.append(tonic)\n",
    "        modes.append(mode)\n",
    "        \n",
    "    df[\"root_tpc\"] = roots\n",
    "    df[\"chord_type\"] = chord_types\n",
    "    df[\"inversion\"] = invs\n",
    "    df[\"tonic\"] = tonics\n",
    "    df[\"mode\"] = modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_df(filename: str) -> pd.DataFrame:\n",
    "    filename = filename[:-21] + \"results.tsv\"\n",
    "    file = glob(f'outputs/**/{filename}', recursive=True)[0]\n",
    "    \n",
    "    return pd.read_csv(file, sep='\\t', index_col=0, converters={'duration': Fraction}), file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_at_onset(df, onset):\n",
    "    index = min(bisect(list(df['off']), float(onset)), len(df) - 1)\n",
    "    return df.iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_df(key, df):\n",
    "    label_df, filename = get_label_df(key)\n",
    "    root_accs = []\n",
    "    chord_accs = []\n",
    "    triad_accs = []\n",
    "    seventh_accs = []\n",
    "    key_accs = []\n",
    "    full_accs = []\n",
    "    \n",
    "    onset = 0\n",
    "    for _, label_row in label_df.iterrows():\n",
    "        est_row = get_row_at_onset(df, onset)\n",
    "        onset += label_row['duration']\n",
    "        \n",
    "        tonic_str = label_row['gt_key'].split(':')[0]\n",
    "        if '/' in tonic_str:\n",
    "            tonic_str = tonic_str.split('/')[0]\n",
    "            \n",
    "        gt_tonic = hu.get_pitch_from_string(tonic_str, pitch_type=PitchType.TPC)\n",
    "        gt_mode = KeyMode.MAJOR if label_row['gt_key'][0].isupper() else KeyMode.MINOR\n",
    "        \n",
    "        gt_chord = label_row['gt_chord']\n",
    "        gt_inv = int(gt_chord[-1])\n",
    "        root_str = gt_chord.split(':')[0]\n",
    "        if '/' in root_str:\n",
    "            root_str = root_str.split('/')[0]\n",
    "        gt_root = hu.get_pitch_from_string(root_str, pitch_type=PitchType.TPC)\n",
    "        gt_chord_type = hu.get_chord_type_from_string(gt_chord.split(':')[1].split(',')[0])\n",
    "        \n",
    "        chord_dist = eu.get_chord_distance(\n",
    "            gt_root,\n",
    "            gt_chord_type,\n",
    "            gt_inv,\n",
    "            est_row['root_tpc'],\n",
    "            est_row['chord_type'],\n",
    "            est_row['inversion'],\n",
    "        )\n",
    "        chord_accs.append(1 - chord_dist)\n",
    "\n",
    "        root_dist = eu.get_chord_distance(\n",
    "            gt_root,\n",
    "            gt_chord_type,\n",
    "            0,\n",
    "            est_row['root_tpc'],\n",
    "            est_row['chord_type'],\n",
    "            0,\n",
    "            reduction=ALL_ONE_TYPE_REDUCTION\n",
    "        )\n",
    "        root_accs.append(1 - root_dist)\n",
    "        \n",
    "        triad_dist = eu.get_chord_distance(\n",
    "            gt_root,\n",
    "            gt_chord_type,\n",
    "            0,\n",
    "            est_row['root_tpc'],\n",
    "            est_row['chord_type'],\n",
    "            0,\n",
    "            reduction=TRIAD_REDUCTION\n",
    "        )\n",
    "        triad_accs.append(1 - triad_dist)\n",
    "        \n",
    "        seventh_dist = eu.get_chord_distance(\n",
    "            gt_root,\n",
    "            gt_chord_type,\n",
    "            0,\n",
    "            est_row['root_tpc'],\n",
    "            est_row['chord_type'],\n",
    "            0,\n",
    "        )\n",
    "        seventh_accs.append(1 - seventh_dist)\n",
    "        \n",
    "        key_dist = eu.get_key_distance(\n",
    "            gt_tonic,\n",
    "            gt_mode,\n",
    "            est_row['tonic'],\n",
    "            est_row['mode'],\n",
    "        )\n",
    "        key_accs.append(1 - key_dist)\n",
    "        \n",
    "        full_accs.append(1 if chord_dist + key_dist == 0 else 0)\n",
    "        \n",
    "    \n",
    "    root_acc = float(np.average(root_accs, weights=label_df['duration']))\n",
    "    chord_acc = float(np.average(chord_accs, weights=label_df['duration']))\n",
    "    key_acc = float(np.average(key_accs, weights=label_df['duration']))\n",
    "    full_acc = float(np.average(full_accs, weights=label_df['duration']))\n",
    "    triad_acc = float(np.average(triad_accs, weights=label_df['duration']))\n",
    "    seventh_acc = float(np.average(seventh_accs, weights=label_df['duration']))\n",
    "    \n",
    "    return {\n",
    "        \"Root\": root_acc,\n",
    "        \"Triad\": triad_acc,\n",
    "        \"Seventh\": seventh_acc,\n",
    "        \"Chord\": chord_acc,\n",
    "        \"Key\": key_acc,\n",
    "        \"Full\": full_acc,\n",
    "    }, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_vals = {}\n",
    "import re\n",
    "\n",
    "for key, df in results.items():\n",
    "    eval_dict, name = evaluate_df(key, df)\n",
    "\n",
    "    if not \"Beethoven\" in name:\n",
    "        continue\n",
    "    print(name)\n",
    "    for acc, val in eval_dict.items():\n",
    "        if acc not in results_vals:\n",
    "            results_vals[acc] = []\n",
    "        results_vals[acc].append(val)\n",
    "        print(f\"    {acc}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acc, val_list in results_vals.items():\n",
    "    print(f\"{acc}: {sum(val_list) / len(val_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from fractions import Fraction\n",
    "\n",
    "import pandas as pd\n",
    "from music21.converter import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m21_score = parse(Path(\"../functional-harmony/data/BPS/scores/bps_01_01.mxl\"))\n",
    "m21_score = m21_score.flattenParts()\n",
    "m21_score = m21_score.stripTies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in m21_score.recurse().notes:\n",
    "    if note.isChord:\n",
    "        chord = note\n",
    "        print(\"Chord\")\n",
    "        for note in chord.notes:\n",
    "            print(note.pitch.name, note.pitch.octave, chord.duration.quarterLength, chord.offset, chord.measureNumber, note.tie, chord.tie)\n",
    "        print(\"End Chord\")\n",
    "    else:\n",
    "        print(note.offset\n",
    "        print(note.pitch.name, note.pitch.octave, note.duration.quarterLength, note.offset, note.measureNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for offset, measure in m21_score.measureOffsetMap().items():\n",
    "    print(offset, measure[0].timeSignature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "import harmonic_inference.data.piece as piece\n",
    "importlib.reload(piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes, measures_df = piece.get_score_piece_from_music_xml(Path(\"../functional-harmony/data/BPS/scores/bps_01_01.mxl\"), \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df[40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(note for note in notes if note.onset[0] in [48, 49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading functional-harmony data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import harmonic_inference.data.piece as piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in tqdm(glob(\"../functional-harmony/data/**/*.mxl\", recursive=True)[173:]):\n",
    "    music_xml_path = Path(file_path)\n",
    "    label_csv_path = music_xml_path.parent.parent / \"chords\" / Path(str(music_xml_path.stem) + \".csv\")\n",
    "\n",
    "    if not label_csv_path.exists():\n",
    "        logging.error(f\"Label file {label_csv_path} does not exist. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(music_xml_path)\n",
    "    score = piece.get_score_piece_from_music_xml(music_xml_path, label_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results / Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from fractions import Fraction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from harmonic_inference.data.data_types import PitchType, ChordType, KeyMode\n",
    "from harmonic_inference.utils.harmonic_utils import get_pitch_from_string, get_chord_type_from_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(path):\n",
    "    dfs = []\n",
    "\n",
    "    for tsv in tqdm(glob(path, recursive=True)):\n",
    "        dfs.append(pd.read_csv(tsv, sep=\"\\t\", converters={\"duration\": Fraction}, index_col=0))\n",
    "\n",
    "    if len(dfs) == 0:\n",
    "        return None\n",
    "\n",
    "    results_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    for type in [\"gt\", \"est\"]:\n",
    "        results_df[f\"{type}_key_tonic\"] = 0\n",
    "        results_df[f\"{type}_key_mode\"] = 0\n",
    "        results_df[f\"{type}_chord_root\"] = 0\n",
    "        results_df[f\"{type}_chord_type\"] = 0\n",
    "        results_df[f\"{type}_chord_inv\"] = 0\n",
    "\n",
    "    keys = np.concatenate((results_df[\"gt_key\"].unique(), results_df[\"est_key\"].unique()))\n",
    "\n",
    "    for key in tqdm(keys, desc=\"Working on keys...\"):\n",
    "        key_tonic, key_mode = key.split(\":\")\n",
    "\n",
    "        for type in [\"gt\", \"est\"]:\n",
    "            results_df.loc[results_df[f\"{type}_key\"] == key, f\"{type}_key_tonic\"] = get_pitch_from_string(key_tonic, PitchType.MIDI)\n",
    "            results_df.loc[results_df[f\"{type}_key\"] == key, f\"{type}_key_mode\"] = KeyMode[key_mode.split(\".\")[1]]\n",
    "\n",
    "    chords = np.concatenate((results_df[\"gt_chord\"].unique(), results_df[\"est_chord\"].unique()))\n",
    "\n",
    "    for chord in tqdm(chords, desc=\"Working on chords...\"):\n",
    "        inv = int(chord[-1])\n",
    "        chord_str = chord.split(\",\")[0]\n",
    "        chord_root, chord_type = chord_str.split(\":\")\n",
    "\n",
    "        for type in [\"gt\", \"est\"]:\n",
    "            results_df.loc[results_df[f\"{type}_chord\"] == chord, f\"{type}_chord_root\"] = get_pitch_from_string(chord_root, PitchType.TPC)\n",
    "            results_df.loc[results_df[f\"{type}_chord\"] == chord, f\"{type}_chord_type\"] = get_chord_type_from_string(chord_type)\n",
    "            results_df.loc[results_df[f\"{type}_chord\"] == chord, f\"{type}_chord_inv\"] = inv\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_results_df(\"outputs/dcml-csm-1/**/*_results.tsv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heat_map_matrix(results_df):\n",
    "    heat_map = np.zeros((len(ChordType), len(ChordType) + 2))\n",
    "\n",
    "    for i, chord_type in tqdm(enumerate(ChordType)):\n",
    "\n",
    "        chord_type_df = results_df.loc[results_df[\"gt_chord_type\"] == chord_type]\n",
    "        if len(chord_type_df) == 0:\n",
    "            continue\n",
    "\n",
    "        total_dur = float(chord_type_df[\"duration\"].sum())\n",
    "\n",
    "        correct_root_df = chord_type_df.loc[chord_type_df[\"gt_chord_root\"] == chord_type_df[\"est_chord_root\"]]\n",
    "        heat_map[i, 0] = float(total_dur - correct_root_df['duration'].sum())\n",
    "\n",
    "        for j, est_chord_type in enumerate(ChordType, start=1):\n",
    "            selected_df = correct_root_df.loc[correct_root_df[\"est_chord_type\"] == est_chord_type]\n",
    "\n",
    "            if est_chord_type == chord_type:\n",
    "                correct_type_df = selected_df\n",
    "\n",
    "            selected_dur = float(selected_df[\"duration\"].sum())\n",
    "\n",
    "            heat_map[i, j] = selected_dur\n",
    "\n",
    "        if len(correct_type_df) > 0:\n",
    "            correct_inv_df = correct_type_df.loc[(correct_root_df[\"gt_chord_inv\"] == correct_root_df[\"est_chord_inv\"])]\n",
    "            heat_map[i, -1] = 1 - float(correct_inv_df['duration'].sum() / correct_type_df['duration'].sum())\n",
    "\n",
    "    return heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_heat_map(heat_map):\n",
    "    for i, row in enumerate(heat_map):\n",
    "        if np.sum(row[:-1]) == 0:\n",
    "            continue\n",
    "        heat_map[i, :-1] /= np.sum(row[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = [\n",
    "    \"M\",\n",
    "    \"m\",\n",
    "    \"o\",\n",
    "    \"+\",\n",
    "    \"MM7\",\n",
    "    \"d7\",\n",
    "    \"mM7\",\n",
    "    \"mm7\",\n",
    "    \"o7\",\n",
    "    \"%7\",\n",
    "    \"+7\",\n",
    "    \"+M7\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = get_heat_map_matrix(results_df)\n",
    "\n",
    "normalize_heat_map(heat_map)\n",
    "\n",
    "plt.xlabel(\"Estimated Chord Type\", labelpad=-15)\n",
    "plt.ylabel(\"Ground Truth Chord Type\", rotation=90)\n",
    "plt.xticks(ticks=np.arange(len(ChordType) + 2), labels=[\"Incorrect Root\"] + xticks + [\"Incorrect Inv.\"], rotation=90)\n",
    "plt.yticks(ticks=np.arange(len(ChordType)), labels=xticks)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.imshow(heat_map, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.savefig(\"figs/heatmap.png\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_heat_map = get_heat_map_matrix(results_df.loc[results_df[\"gt_key_mode\"] == KeyMode.MAJOR])\n",
    "\n",
    "normalize_heat_map(major_heat_map)\n",
    "\n",
    "plt.xlabel(\"Estimated Chord Type\", labelpad=-15)\n",
    "plt.ylabel(\"Ground Truth Chord Type\", rotation=90)\n",
    "plt.xticks(ticks=np.arange(len(ChordType) + 2), labels=[\"Incorrect Root\"] + xticks + [\"Incorrect Inv.\"], rotation=90)\n",
    "plt.yticks(ticks=np.arange(len(ChordType)), labels=xticks)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.imshow(major_heat_map, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.savefig(\"figs/heatmap_major.png\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_heat_map = get_heat_map_matrix(results_df.loc[results_df[\"gt_key_mode\"] == KeyMode.MINOR])\n",
    "\n",
    "normalize_heat_map(minor_heat_map)\n",
    "\n",
    "plt.xlabel(\"Estimated Chord Type\", labelpad=-15)\n",
    "plt.ylabel(\"Ground Truth Chord Type\", rotation=90)\n",
    "plt.xticks(ticks=np.arange(len(ChordType) + 2), labels=[\"Incorrect Root\"] + xticks + [\"Incorrect Inv.\"], rotation=90)\n",
    "plt.yticks(ticks=np.arange(len(ChordType)), labels=xticks)\n",
    "plt.imshow(minor_heat_map, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(\"figs/heatmap_minor.png\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_given_inversion(results_df, inv):\n",
    "    inv_df = results_df.loc[results_df[\"gt_chord_inv\"] == inv]\n",
    "\n",
    "    correct_df = inv_df.loc[inv_df[\"gt_chord\"] == inv_df[\"est_chord\"]]\n",
    "\n",
    "    return float(correct_df[\"duration\"].sum() / inv_df[\"duration\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_results_df(\"outputs/dcml-csm-1/**/*_results.tsv\")\n",
    "for inv in range(4):\n",
    "    print(f\"Inv {inv} {get_acc_given_inversion(results_df, inv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(results_df):\n",
    "    total_dur = float(results_df[\"duration\"].sum())\n",
    "    correct_dur = float(\n",
    "        results_df.loc[\n",
    "            (\n",
    "                (results_df[\"gt_key\"] == results_df[\"est_key\"]) &\n",
    "                (results_df[\"gt_chord\"] == results_df[\"est_chord\"])\n",
    "            ),\n",
    "            \"duration\",\n",
    "        ].sum()\n",
    "    )\n",
    "\n",
    "    return correct_dur / total_dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_results_df(\"outputs/dcml-csm-1/**/*_results.tsv\")\n",
    "acc = get_acc(results_df)\n",
    "acc_minor = get_acc(results_df.loc[results_df[\"gt_key_mode\"] == KeyMode.MINOR])\n",
    "acc_major = get_acc(results_df.loc[results_df[\"gt_key_mode\"] == KeyMode.MAJOR])\n",
    "\n",
    "print(f\"Overall: {acc}\")\n",
    "print(f\"Minor: {acc_minor}\")\n",
    "print(f\"Major: {acc_major}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chord_type in ChordType:\n",
    "    try:\n",
    "        print(f\"{chord_type}: {get_acc(results_df.loc[results_df['gt_chord_type'] == chord_type])}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_type_heat_map = np.zeros((len(KeyMode), len(ChordType)))\n",
    "\n",
    "for i, mode in enumerate(KeyMode):\n",
    "    for j, chord_type in enumerate(ChordType):\n",
    "        try:\n",
    "            acc = get_acc(results_df.loc[(results_df['gt_chord_type'] == chord_type) & (results_df['gt_key_mode'] == mode)])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        print(f\"{mode}, {chord_type} = {acc}\")\n",
    "        mode_type_heat_map[i, j] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Chord Type\", fontsize=12)\n",
    "plt.ylabel(\"Mode\", rotation=90, fontsize=12)\n",
    "plt.xticks(ticks=np.arange(len(ChordType)), labels=xticks, rotation=90, fontsize=12)\n",
    "plt.yticks(ticks=np.arange(len(KeyMode)), labels=[\"Major\", \"Minor\"], fontsize=12)\n",
    "plt.imshow(mode_type_heat_map, vmin=0, vmax=1)\n",
    "plt.colorbar(orientation=\"horizontal\", shrink=0.5, pad=0.23)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(\"figs/acc_by_mode_type.png\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = {}\n",
    "\n",
    "for dir in glob(\"outputs/dcml-csm-1/*\"):\n",
    "    results_df_comp = get_results_df(dir + \"/**/*_results.tsv\")\n",
    "    if results_df_comp is None:\n",
    "        continue\n",
    "\n",
    "    accs[dir.split(\"/\")[-1]] = get_acc(results_df_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in accs.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting results TSV to chord-eval comparison for ICMPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from harmonic_inference.data.data_types import ChordType, PitchType, TRIAD_REDUCTION\n",
    "from harmonic_inference.utils.harmonic_constants import STRING_TO_CHORD_TYPE\n",
    "from harmonic_inference.utils.harmonic_utils import get_pitch_from_string, get_pitch_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = \"outputs/icmpc/*/Mozart-Sonatas/*_results.tsv\"\n",
    "\n",
    "for results_tsv in tqdm(glob(in_path)):\n",
    "    results_df = pd.read_csv(results_tsv, sep=\"\\t\")\n",
    "\n",
    "    for prefix in [\"gt\", \"est\"]:\n",
    "        results_df[f\"{prefix}_chord_root\"] = 0\n",
    "        results_df[f\"{prefix}_chord_type\"] = 0\n",
    "        results_df[f\"{prefix}_chord_inv\"] = 0\n",
    "    results_df[\"root_correct\"] = 0\n",
    "    results_df[\"triad_correct\"] = 0\n",
    "    results_df[\"7th_correct\"] = 0\n",
    "    results_df[\"inv_correct\"] = 0\n",
    "    results_df[\"full_correct\"] = 0\n",
    "\n",
    "    for idx, row in results_df.iterrows():\n",
    "        gt_root_str, gt_other_str, gt_inv_str = row[\"gt_chord\"].split(\":\")\n",
    "        gt_chord_type_str, _ = gt_other_str.split(\",\")\n",
    "\n",
    "        gt_root = get_pitch_from_string(gt_root_str, PitchType.MIDI)\n",
    "        gt_chord_type = STRING_TO_CHORD_TYPE[gt_chord_type_str]\n",
    "\n",
    "        est_root_str, est_other_str, est_inv_str = row[\"est_chord\"].split(\":\")\n",
    "        est_chord_type_str, _ = est_other_str.split(\",\")\n",
    "\n",
    "        est_root = get_pitch_from_string(est_root_str, PitchType.MIDI)\n",
    "        est_chord_type = STRING_TO_CHORD_TYPE[est_chord_type_str]\n",
    "\n",
    "        results_df.loc[idx, \"gt_chord_root\"] = gt_root\n",
    "        results_df.loc[idx, \"gt_chord_type\"] = str(gt_chord_type)\n",
    "        results_df.loc[idx, \"gt_chord_inv\"] = gt_inv_str\n",
    "        results_df.loc[idx, \"est_chord_root\"] = est_root\n",
    "        results_df.loc[idx, \"est_chord_type\"] = str(est_chord_type)\n",
    "        results_df.loc[idx, \"est_chord_inv\"] = est_inv_str\n",
    "\n",
    "        results_df.loc[idx, \"root_correct\"] = gt_root == est_root\n",
    "        results_df.loc[idx, \"triad_correct\"] = TRIAD_REDUCTION[gt_chord_type] == TRIAD_REDUCTION[est_chord_type]\n",
    "        results_df.loc[idx, \"7th_correct\"] = gt_chord_type == est_chord_type\n",
    "        results_df.loc[idx, \"inv_correct\"] = gt_inv_str == est_inv_str\n",
    "        results_df.loc[idx, \"full_correct\"] = gt_inv_str == est_inv_str and gt_root == est_root and gt_chord_type == est_chord_type\n",
    "\n",
    "    tsv_path = Path(results_tsv)\n",
    "    out_path = tsv_path.parent / (tsv_path.name[:-4] + \"chord-eval.tsv\")\n",
    "    results_df.to_csv(out_path, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff434d933de17a983dcdcea9c2acfb61be3ec6adbf2e7b32a2f4ca8c018973b7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('harmony': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "a57f58e30d212928e74c5602bd4e8e4f092b6859f430ed58a42bf66140f5df95"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
